{
    "2104.09677_5": {
        "html_table": "<table><tbody><tr><td rowspan=\"3\"><span>Runtime</span></td><td><table><span>Attribute selection step (Algorithm1)</span></table></td><td><span>7,903</span></td></tr><tr><td><table><span>Signature generation step (Algorithm2)</span></table></td><td><span>4,573</span></td></tr><tr><td><table><span>Record matching step (Algorithm3)</span></table></td><td><span>3,438</span></td></tr><tr><td rowspan=\"2\"><span>Linkage quality</span></td><td><span>Precision</span></td><td><span>0.999</span></td></tr><tr><td><span>Recall</span></td><td><span>0.962</span></td></tr></tbody></table></figure>",
        "table_head": "<table><tbody><tr><td rowspan=\"3\"><span>Runtime</span></td><td><table><span>Attribute selection step (Algorithm1)</span></table></td><td><span>7,903</span></td></tr></tbody></table>",
        "citations": [
            "Results and Discussion:  Table5 shows the runtime and linkage quality results our approach achieved linking these two census data sets. As can be seen, our approach completed the linkage in less than 5 hours. Our approach generated approximately 400 million unique attribute signatures in Algorithm2 when we selected the five best attribute combinations in Algorithm1, and set the score weight as =0.50.5\\alpha=0.5 and attribute selection threshold as ct=0.6subscript0.6c_{t}=0.6, respectively. As shown in Table5, our approach achieved an overall precision and recall of 0.999 and 0.962, respectively, which involves the comparison of approximately 54 million candidate record pairs."
        ],
        "caption": "Table 5. Average runtime (in seconds) and linkage quality results with st=0.8subscript0.8s_{t}=0.8 for German census data sets.",
        "footnotes": [""]
    },
    "2503.24193_3": {
        "caption": "Effectiveness of Text2Tracks and competing models. Bold denotes the highest effectiveness for hits@10.",
        "table": "<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>How it works</th>\n      <th>hits@10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>BM25</td>\n      <td>Keyword indexing</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder zero-shot</td>\n      <td>Semantic match between playlist titles</td>\n      <td>0.065</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder fine-tuned</td>\n      <td>Fine-tuned semantic match between playlist titles</td>\n      <td>0.119</td>\n    </tr>\n    <tr>\n      <td><b>Text2Tracks</b></td>\n      <td><b>GR using cf-based semantic-ids</b></td>\n      <td><b>0.270</b></td>\n    </tr>\n  </tbody>\n</table>",
        "html_table": "<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>How it works</th>\n      <th>hits@10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>BM25</td>\n      <td>Keyword indexing</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder zero-shot</td>\n      <td>Semantic match between playlist titles</td>\n      <td>0.065</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder fine-tuned</td>\n      <td>Fine-tuned semantic match between playlist titles</td>\n      <td>0.119</td>\n    </tr>\n    <tr>\n      <td><b>Text2Tracks</b></td>\n      <td><b>GR using cf-based semantic-ids</b></td>\n      <td><b>0.270</b></td>\n    </tr>\n  </tbody>\n</table>",
        "og_table": "<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>How it works</th>\n      <th>hits@10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>BM25</td>\n      <td>Keyword indexing</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder zero-shot</td>\n      <td>Semantic match between playlist titles</td>\n      <td>0.065</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder fine-tuned</td>\n      <td>Fine-tuned semantic match between playlist titles</td>\n      <td>0.119</td>\n    </tr>\n    <tr>\n      <td><b>Text2Tracks</b></td>\n      <td><b>GR using cf-based semantic-ids</b></td>\n      <td><b>0.270</b></td>\n    </tr>\n  </tbody>\n</table>",
        "table_head": "<table>\n  <thead>\n    <tr>\n      <th>Model</th>\n      <th>How it works</th>\n      <th>hits@10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>BM25</td>\n      <td>Keyword indexing</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder zero-shot</td>\n      <td>Semantic match between playlist titles</td>\n      <td>0.065</td>\n    </tr>\n    <tr>\n      <td>Bi-encoder fine-tuned</td>\n      <td>Fine-tuned semantic match between playlist titles</td>\n      <td>0.119</td>\n    </tr>\n    <tr>\n      <td><b>Text2Tracks</b></td>\n      <td><b>GR using cf-based semantic-ids</b></td>\n      <td><b>0.270</b></td>\n    </tr>\n  </tbody>\n</table>",
        "citations": [
        "How does Text2Tracks compare to baselines that retrieve tracks based on a language prompt? We display in Table 3 the results for the task of generative track retrieval. We see that Text2Tracks outperforms the baselines, obtaining a 127% increase in hits@10 with respect to the closest competitor. This proves the effectiveness of Generative Retrieval in this task, as directly finetuning a model to generate track identifiers significantly outperforms commonly used techniques that rely on indexing and retrieving track vectors"
        ]
    },
    "1308.3357_1": {
            "table": "<table><thead><tr><th><span>Serialisation</span></th><th><span>Size (kB/1K triples)</span></th></tr></thead><tbody><tr><th>N-Triples</th><td>157</td></tr><tr><th>Model 1</th><td>143</td></tr><tr><th>Model 2</th><td>157</td></tr><tr><th>Document per quad</th><td>418</td></tr></tbody></table>",
            "html_table": "<table><thead><tr><th><span>Serialisation</span></th><th><span>Size (kB/1K triples)</span></th></tr></thead><tbody><tr><th>N-Triples</th><td>157</td></tr><tr><th>Model 1</th><td>143</td></tr><tr><th>Model 2</th><td>157</td></tr><tr><th>Document per quad</th><td>418</td></tr></tbody></table>",
            "table_head": "<table><thead><tr><th><span>Serialisation</span></th><th><span>Size (kB/1K triples)</span></th></tr></thead><tbody><tr><th>N-Triples</th><td>157</td></tr><tr><th>Model 1</th><td>143</td></tr><tr><th>Model 2</th><td>157</td></tr><tr><th>Document per quad</th><td>418</td></tr></tbody></table>",
            "citations": [
                "An estimate of disk space required for storing the standard SP2superscript2SP^{2}bench dataset using these serialization models is given in Table1. For this experiment we switched off the database file compression in CouchDB. Disk usage is very similar in all three cases and thus not a decisive factor."
            ],
            "caption": "Table 1: Storage requirements of different serialization models.",
            "processed": false
    },
    "2404.05566_3": {
            "table": "<table><thead><tr><th>Rank</th><th>Training</th><th>Test</th></tr></thead><tbody><tr><th>1</th><td>76.74</td><td>79.55</td></tr><tr><th>2</th><td>4.92</td><td>4.19</td></tr><tr><th>3</th><td>1.76</td><td>1.14</td></tr><tr><th>4</th><td>1.09</td><td>0.64</td></tr><tr><th><math><semantics><mo></mo><annotation-xml><geq></geq></annotation-xml><annotation>\\geq</annotation></semantics></math> 5</th><td>15.49</td><td>14.48</td></tr></tbody></table></figure>",
            "html_table": "<table><thead><tr><th>Rank</th><th>Training</th><th>Test</th></tr></thead><tbody><tr><th>1</th><td>76.74</td><td>79.55</td></tr><tr><th>2</th><td>4.92</td><td>4.19</td></tr><tr><th>3</th><td>1.76</td><td>1.14</td></tr><tr><th>4</th><td>1.09</td><td>0.64</td></tr><tr><th><math><semantics><mo></mo><annotation-xml><geq></geq></annotation-xml><annotation>\\geq</annotation></semantics></math> 5</th><td>15.49</td><td>14.48</td></tr></tbody></table>",
            "table_head": "<table><thead><tr><th>Rank</th><th>Training</th><th>Test</th></tr></thead><tbody><tr><th>1</th><td>76.74</td><td>79.55</td></tr><tr><th>2</th><td>4.92</td><td>4.19</td></tr><tr><th>3</th><td>1.76</td><td>1.14</td></tr><tr><th>4</th><td>1.09</td><td>0.64</td></tr><tr><th><math><semantics><mo></mo><annotation-xml><geq></geq></annotation-xml><annotation>\\geq</annotation></semantics></math> 5</th><td>15.49</td><td>14.48</td></tr></tbody></table>",
            "citations": [
                "To gain insights into the estimated probabilities of a match, we assess the rank of these probabilities for each household in 201420142014 in relation to the corresponding true matches in the 201620162016 database. For each split, the estimated probabilities of a match between a 201420142014 household and all 201620162016 households are ranked in descending order. Accurate model estimates would position the true matching household at the top. Table3 presents the average percentage of actual matching households occupying the first position in the predicted probabilities, ranked in descending order, for both the training and test sets. The table shows that, on average, approximately 76.74%percent76.7476.74\\% of the highest probability from the model corresponds to the true match in the training data. For the test data, this value is 79.55%percent79.5579.55\\%. Moreover, the top three positions correspond, on average, to actually matching pairs in around 85%percent8585\\% of the cases for both training and test sets. The results indicate that selecting the top three households with the highest probability of a match will likely include the true match in the selection."
            ],
            "caption": "Table 3: Rank of the probability of the correctly matching household. The rank 111 indicates that the highest probability is associated with the 201620162016 household which is the correct match. Likewise, rank 222 implies that the match had the second-highest probability, and so on.",
            "processed": false
    },
    "1906.11180_2": {
            "table": "<table><thead><tr><th colspan=\"2\"><span>Framework</span></th><th colspan=\"2\"><span>Independent</span></th><th colspan=\"2\"><span>Hierarchical (</span><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo></mo><mn>0.1</mn></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><apply><minus></minus><cn>0.1</cn></apply></apply></annotation-xml><annotation>\\kappa=-0.1</annotation></semantics></math><span>)</span></th><th colspan=\"2\"><span>Hierarchical (</span><math><semantics><mrow><mi></mi><mo>=</mo><mn>0</mn></mrow><annotation-xml><apply><eq></eq><ci></ci><cn>0</cn></apply></annotation-xml><annotation>\\kappa=0</annotation></semantics></math><span>)</span></th></tr><tr><th colspan=\"2\"><span>Settings</span></th><th><span><span><span>AvgF1@all</span></span></span></th><th><span>AvgF1@top</span><math><semantics><mn>5</mn><annotation-xml><cn>5</cn></annotation-xml><annotation>5</annotation></semantics></math></th><th><span><span><span>AvgF1@all</span></span></span></th><th><span>AvgF1@top</span><math><semantics><mn>5</mn><annotation-xml><cn>5</cn></annotation-xml><annotation>5</annotation></semantics></math></th><th><span><span><span>AvgF1@all</span></span></span></th><th><span>AvgF1@top</span><math><semantics><mn>5</mn><annotation-xml><cn>5</cn></annotation-xml><annotation>5</annotation></semantics></math></th></tr></thead><tbody><tr><td><span><span><span>Pre-training</span></span></span></td><td><span><span><span>MLP</span></span></span></td><td><span><span><math><semantics><mn>0.4102</mn><annotation-xml><cn>0.4102</cn></annotation-xml><annotation>0.4102</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.4832</mn><annotation-xml><cn>0.4832</cn></annotation-xml><annotation>0.4832</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.5060</mn><annotation-xml><cn>0.5060</cn></annotation-xml><annotation>0.5060</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5458</mn><annotation-xml><cn>0.5458</cn></annotation-xml><annotation>0.5458</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.5916</mn><annotation-xml><cn>0.5916</cn></annotation-xml><annotation>0.5916</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5923</mn><annotation-xml><cn>0.5923</cn></annotation-xml><annotation>0.5923</annotation></semantics></math></td></tr><tr><td><span><span></span></span></td><td><span><span><span>BiRNN</span></span></span></td><td><span><span><math><semantics><mn>0.4686</mn><annotation-xml><cn>0.4686</cn></annotation-xml><annotation>0.4686</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5566</mn><annotation-xml><cn>0.5566</cn></annotation-xml><annotation>0.5566</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.5295</mn><annotation-xml><cn>0.5295</cn></annotation-xml><annotation>0.5295</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5649</mn><annotation-xml><cn>0.5649</cn></annotation-xml><annotation>0.5649</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.5977</mn><annotation-xml><cn>0.5977</cn></annotation-xml><annotation>0.5977</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5985</mn><annotation-xml><cn>0.5985</cn></annotation-xml><annotation>0.5985</annotation></semantics></math></td></tr><tr><td><span><span></span></span></td><td><span><span><span>AttBiRNN</span></span></span></td><td><span><span><math><semantics><mn>0.4728</mn><annotation-xml><cn>0.4728</cn></annotation-xml><annotation>0.4728</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5590</mn><annotation-xml><cn>0.5590</cn></annotation-xml><annotation>0.5590</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.5420</mn><annotation-xml><cn>0.5420</cn></annotation-xml><annotation>0.5420</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.5912</mn><annotation-xml><cn>0.5912</cn></annotation-xml><annotation>0.5912</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.6049</mn><annotation-xml><cn>0.6049</cn></annotation-xml><annotation>0.6049</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.6052</mn><annotation-xml><cn>0.6052</cn></annotation-xml><annotation>0.6052</annotation></semantics></math></td></tr><tr><td><span><span><span>Fine tuning</span></span></span></td><td><span><span><span>MLP</span></span></span></td><td><span><span><math><semantics><mn>0.6506</mn><annotation-xml><cn>0.6506</cn></annotation-xml><annotation>0.6506</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.6948</mn><annotation-xml><cn>0.6948</cn></annotation-xml><annotation>0.6948</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.6859</mn><annotation-xml><cn>0.6859</cn></annotation-xml><annotation>0.6859</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.6989</mn><annotation-xml><cn>0.6989</cn></annotation-xml><annotation>0.6989</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.6429</mn><annotation-xml><cn>0.6429</cn></annotation-xml><annotation>0.6429</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.6626</mn><annotation-xml><cn>0.6626</cn></annotation-xml><annotation>0.6626</annotation></semantics></math></td></tr><tr><td><span><span></span></span></td><td><span><span><span>BiRNN</span></span></span></td><td><span><span><math><semantics><mn>0.7008</mn><annotation-xml><cn>0.7008</cn></annotation-xml><annotation>0.7008</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.7434</mn><annotation-xml><cn>0.7434</cn></annotation-xml><annotation>0.7434</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.7167</mn><annotation-xml><cn>0.7167</cn></annotation-xml><annotation>0.7167</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.7372</mn><annotation-xml><cn>0.7372</cn></annotation-xml><annotation>0.7372</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.6697</mn><annotation-xml><cn>0.6697</cn></annotation-xml><annotation>0.6697</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.6850</mn><annotation-xml><cn>0.6850</cn></annotation-xml><annotation>0.6850</annotation></semantics></math></td></tr><tr><td><span><span></span></span></td><td><span><span><span>AttBiRNN</span></span></span></td><td><span><span><math><semantics><mn>0.7286</mn><annotation-xml><cn>0.7286</cn></annotation-xml><annotation>0.7286</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.7557</mn><annotation-xml><cn>0.7557</cn></annotation-xml><annotation>0.7557</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.7429</mn><annotation-xml><cn>0.7429</cn></annotation-xml><annotation>0.7429</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.7601</mn><annotation-xml><cn>0.7601</cn></annotation-xml><annotation>0.7601</annotation></semantics></math></td><td><span><span><math><semantics><mn>0.6918</mn><annotation-xml><cn>0.6918</cn></annotation-xml><annotation>0.6918</annotation></semantics></math></span></span></td><td><math><semantics><mn>0.7070</mn><annotation-xml><cn>0.7070</cn></annotation-xml><annotation>0.7070</annotation></semantics></math></td></tr></tbody></table>",
            "html_table":"<table><thead><tr><th colspan=2>Framework</th><th colspan=2>Independent</th><th colspan=2>Hierarchical (= -0.1)</th><th colspan=2>Hierarchical (= 0)</th></tr><tr><th colspan=2>Settings</th><th>AvgF1@all</th><th>AvgF1@top5</th><th>AvgF1@all</th><th>AvgF1@top5</th><th>AvgF1@all</th><th>AvgF1@top5</th></tr></thead><tbody><tr><td>Pre-training</td><td>MLP</td><td>0.4102</td><td>0.4832</td><td>0.5060</td><td>0.5458</td><td>0.5916</td><td>0.5923</td></tr><tr><td></td><td>BiRNN</td><td>0.4686</td><td>0.5566</td><td>0.5295</td><td>0.5649</td><td>0.5977</td><td>0.5985</td></tr><tr><td></td><td>AttBiRNN</td><td>0.4728</td><td>0.5590</td><td>0.5420</td><td>0.5912</td><td>0.6049</td><td>0.6052</td></tr><tr><td>Fine tuning</td><td>MLP</td><td>0.6506</td><td>0.6948</td><td>0.6859</td><td>0.6989</td><td>0.6429</td><td>0.6626</td></tr><tr><td></td><td>BiRNN</td><td>0.7008</td><td>0.7434</td><td>0.7167</td><td>0.7372</td><td>0.6697</td><td>0.6850</td></tr><tr><td></td><td>AttBiRNN</td><td>0.7286</td><td>0.7557</td><td>0.7429</td><td>0.7601</td><td>0.6918</td><td>0.7070</td></tr></tbody></table>",
            "table_head": "<table><thead><tr><th colspan=2>Framework</th><th colspan=2>Independent</th><th colspan=2>Hierarchical (= -0.1)</th><th colspan=2>Hierarchical (= 0)</th></tr><tr><th colspan=2>Settings</th><th>AvgF1@all</th><th>AvgF1@top5</th><th>AvgF1@all</th><th>AvgF1@top5</th><th>AvgF1@all</th><th>AvgF1@top5</th></tr></thead><tbody><tr><td>Pre-training</td><td>MLP</td><td>0.4102</td><td>0.4832</td><td>0.5060</td><td>0.5458</td><td>0.5916</td><td>0.5923</td></tr><tr><td></td><td>BiRNN</td><td>0.4686</td><td>0.5566</td><td>0.5295</td><td>0.5649</td><td>0.5977</td><td>0.5985</td></tr><tr><td></td><td>AttBiRNN</td><td>0.4728</td><td>0.5590</td><td>0.5420</td><td>0.5912</td><td>0.6049</td><td>0.6052</td></tr><tr><td>Fine tuning</td><td>MLP</td><td>0.6506</td><td>0.6948</td><td>0.6859</td><td>0.6989</td><td>0.6429</td><td>0.6626</td></tr><tr><td></td><td>BiRNN</td><td>0.7008</td><td>0.7434</td><td>0.7167</td><td>0.7372</td><td>0.6697</td><td>0.6850</td></tr><tr><td></td><td>AttBiRNN</td><td>0.7286</td><td>0.7557</td><td>0.7429</td><td>0.7601</td><td>0.6918</td><td>0.7070</td></tr></tbody></table>",
            "citations": [
                "We first evaluate the impact of the neural network architecture, fine tuning and different typing strategies, with their typing results on S-Lite shown in Table 2 and Fig.3. Our findings are supported by comparable results on R-Lite. We further evaluate sample refinement, with some statistics of the refinement operations as well as performance improvements shown in Fig.4.",
                "According to Table 2, we find BiRNN significantly outperforms Multiple Layer Perceptron (MLP), a basic but widely used neural network model, while stacking an attention layer (AttBiRNN) further improves AvgF1@all and AvgF1@top555, for example by 3.7%percent3.73.7\\% and 3.1%percent3.13.1\\% respectively with hierarchical typing (\\kappa = 0.10.1-0.1). The result is consistent for both pre-trained models and fine tuned models, using both independent and hierarchical typing strategies. This indicates the effectiveness of our neural network architecture. Meanwhile, the performance of all the models is significantly improved after they are fine tuned by the particular samples, as expected. For example, when the independent typing strategy is used, AvgF1@all and AvgF1@top555 of AttBiRNN are improved by 54.1%percent54.154.1\\% and 35.2%percent35.235.2\\% respectively.",
                "The impact of independent and hierarchical typing strategies is more complex. As shown in Table 2, when the classifier is weak (e.g., pre-trained BiRNN), hierarchical typing with both hard exclusion (\\kappa = 00) and relaxed exclusion (\\kappa = 0.10.1-0.1) has higher AvgF1@all and AvgF1@top555 than independent typing. However, when a strong classifier (e.g., fine tuned AttBiRNN) is used, AvgF1@all and AvgF1@top555 of hierarchical typing with relaxed exclusion are close to independent typing, while hierarchical typing with hard exclusion has worse performance. We further analyze Precision, Recall and F1 Score of both typing strategies under varying threshold (\\theta) values, as shown in Fig.3. In comparison with independent typing, hierarchical typing achieves (i) more stable Precision, Recall and F1 Score curves; and (ii) significantly higher Precision, especially when \\theta is small. Meanwhile, as with the results in Table2, relaxed exclusion outperforms hard exclusion in hierarchical typing except for Precision when \\theta is between 00 and 0.050.050.05.",
                "We developed some strategies to fully train our neural networks with the supervision of the KB itself. One strategy is the separated extraction of general samples and particular samples. It (i) eliminates the time consuming pre-training step from a specific task, reducing for example the total typing time per literal of S-Lite from 10.510.510.5 seconds to 2.52.52.5 seconds (training and prediction are run with at most 101010 parallel threads), and (ii) adapts the domain of the classifier toward the target literals through fine tuning, which significantly improves the accuracy as shown in Table2. Another strategy that has been evaluated in Section 3.2 is sample refinement by validating entity classifications with external knowledge from Wikidata. However, we believe that this could be further extended with more external KBs, as well as with logical constraints and rules."
            ],
            "caption": "Table 2: Typing performance of our framework on S-Lite under different settings.",
            "processed": false
    },
    "2310.12450_3": {
            "table": "<div><span><table><tr><td>Method</td><td>HO</td><td>MC</td><td>AS</td><td>LO</td></tr><tr><td>Baseline</td><td>87.64</td><td>77.27</td><td>75.89</td><td>71.46</td></tr><tr><td>BLINK*</td><td>94.30</td><td>75.40</td><td><span>79.95</span></td><td>73.50</td></tr><tr><td>Uni-MPR</td><td>91.43</td><td>79.07</td><td>75.60</td><td>73.53</td></tr><tr><td>Bi-MPR</td><td>92.84</td><td><span>81.93</span></td><td>77.37</td><td>73.88</td></tr><tr><td>ReS</td><td><span>94.42</span></td><td>81.29</td><td>77.80</td><td><span>76.51</span></td></tr><tr><td>ReS (w/o selecting)</td><td>92.72</td><td>78.30</td><td>79.00</td><td>75.50</td></tr></table></span></div>",
            "html_table": "<div><span><table><tr><td>Method</td><td>HO</td><td>MC</td><td>AS</td><td>LO</td></tr><tr><td>Baseline</td><td>87.64</td><td>77.27</td><td>75.89</td><td>71.46</td></tr><tr><td>BLINK*</td><td>94.30</td><td>75.40</td><td><span>79.95</span></td><td>73.50</td></tr><tr><td>Uni-MPR</td><td>91.43</td><td>79.07</td><td>75.60</td><td>73.53</td></tr><tr><td>Bi-MPR</td><td>92.84</td><td><span>81.93</span></td><td>77.37</td><td>73.88</td></tr><tr><td>ReS</td><td><span>94.42</span></td><td>81.29</td><td>77.80</td><td><span>76.51</span></td></tr><tr><td>ReS (w/o selecting)</td><td>92.72</td><td>78.30</td><td>79.00</td><td>75.50</td></tr></table></span></div>",
            "table_head": "<div><span><table><tr><td>Method</td><td>HO</td><td>MC</td><td>AS</td><td>LO</td></tr><tr><td>Baseline</td><td>87.64</td><td>77.27</td><td>75.89</td><td>71.46</td></tr><tr><td>BLINK*</td><td>94.30</td><td>75.40</td><td><span>79.95</span></td><td>73.50</td></tr><tr><td>Uni-MPR</td><td>91.43</td><td>79.07</td><td>75.60</td><td>73.53</td></tr><tr><td>Bi-MPR</td><td>92.84</td><td><span>81.93</span></td><td>77.37</td><td>73.88</td></tr><tr><td>ReS</td><td><span>94.42</span></td><td>81.29</td><td>77.80</td><td><span>76.51</span></td></tr><tr><td>ReS (w/o selecting)</td><td>92.72</td><td>78.30</td><td>79.00</td><td>75.50</td></tr></table></span></div>",
            "citations": [
                "According to the fact that the performance of candidate retrieval models in Multiple Categories and Low Overlap subsets is much lower than the other two subsetsSui etal. (2022), we conjecture that mentions in MC and LO are more difficult and ambiguous, and require more complex reasoning. As Table3 shows, ReS achieves the state-of-the-art performance in the LO subset. Compared with BLINK*, the improvement is the most notable in the MC subset with a 5.89% gain. This indicates that our ReS framework has the reasoning ability to compare candidates and choose the best one.",
                "For the ablation of the selecting module, we consider a variant of ReS: remove the selecting module altogether, use the mention-aware entity representations (i.e., prefix tokens) from the reading module to obtain candidates scores, thus without cross-entity interaction. Table2 shows that removing the selecting module causes a performance drop across all test domains, leading to a 1.61% micro-averaged accuracy drop. Based on Table3, compared with ReS (w/o selecting), ReS improves the most in the Multiple Categories subset. This indicates that cross-entity interaction is helpful in disambiguating lexically similar entities, which is in line with our motivation for fine-grained comparison among candidates illustrated in the case in Figure1. More cases will be discussed in Section4.7.",
                "In addition, for the ablation of the reading module, we can compare the performance of BLINK* and ReS (w/o selecting): For mention-aware entity representations, BLINK* uses the [CLS] token while ReS uses the Prefix tokens. According to Table2, ReS (w/o selecting) outperforms BLINK* by an overall of 1.72% micro-averaged accuracy. Based on fine-grained results of 4 categories in Table3, our prefix token embeddings achieve better performance on Multiple Categories and Low Overlap subsets, the aforementioned two relatively challenging subsets. These experimental results suggest that our reading module can better aggregate information from mention context and entity description, and thus create a better mention-aware entity representation."
            ],
            "caption": "Table 3: Accuracy on the category-specific subsets including High Overlap (HO), Multiple Categories (MC), Ambiguous Substring (AS), Low Overlap (LO). * means our implementation.",
            "processed": false
    },
    "2312.03987_7":  {
        "html_table": "<table><tr><td rowspan=\"2\"><span>Dataset</span></td><td colspan=\"2\"><span>Structure-aware</span></td><td><span>Semantics-based</span></td></tr><tr><td><span>BatchER<span>-LR</span></span></td><td><span>BatchER<span>-JAC</span></span></td><td><span>BatchER<span>-SEM</span></span></td></tr><tr><td><span>WA</span></td><td><span>80.66</span></td><td>78.05</td><td><span>78.66</span></td></tr><tr><td><span>AB</span></td><td><span>88.38</span></td><td>84.23</td><td><span>87.06</span></td></tr><tr><td><span>AG</span></td><td><span>62.16</span></td><td><span>59.90</span></td><td>59.20</td></tr><tr><td><span>DS</span></td><td><span>83.70</span></td><td><span>81.27</span></td><td>80.91</td></tr><tr><td><span>DA</span></td><td><span>94.96</span></td><td><span>92.70</span></td><td>90.36</td></tr><tr><td><span>FZ</span></td><td><span>100.00</span></td><td>93.62</td><td><span>95.24</span></td></tr><tr><td><span>IA</span></td><td><span>96.43</span></td><td>90.57</td><td><span>90.91</span></td></tr><tr><td><span>Beer</span></td><td><span>96.55</span></td><td>89.66</td><td><span>91.67</span></td></tr></table>",
        "table_head": "<table><tr><td rowspan=\"2\"><span>Dataset</span></td><td colspan=\"2\"><span>Structure-aware</span></td><td><span>Semantics-based</span></td></tr><tr><td><span>BatchER<span>-LR</span></span></td><td><span>BatchER<span>-JAC</span></span></td><td><span>BatchER<span>-SEM</span></span></td></tr><tr><td><span>WA</span></td><td><span>80.66</span></td><td>78.05</td><td><span>78.66</span></td></tr></table>",
        "citations": [
            "As shown in TableVII, BatchER-LR achieves the best performance on all the datasets while BatchER-JAC and BatchER-SEM achieve comparative results. This results validates that stucture-aware feature extractor can better capture the relevance between entity pairs in the ER scenario. Moreover, compared with BatchER-JAC, BatchER-LR is more sensitivity to string order and its superior precision in quantifying the similarity between two strings. For instance, considering two strings listen and silent, the similarity score calculated using LR is 0.5, whereas with JAC, it is 0.89. This clearly demonstrates the former is better effectiveness in quantifying the similarity between the two strings, thus is more effective to generate feature vectors for entity pairs."
        ],
        "caption": "TABLE VII: Evaluating Different Feature Extractors on Matching Accuracy (The best results are bolded).",
        "footnotes": [""]
    },
    "1711.07424_2": {
        "table": "<figure><table><thead><tr><th>Region</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>Average</th></tr></thead><tbody><tr><td>GB vs RW</td><td>0.8</td><td>2.9</td><td>0.7</td><td>1.7</td><td>1.4</td><td>0.5</td><td>1.0</td><td>0.9</td><td>0.94</td></tr><tr><td>LB vs RW</td><td>60.6</td><td>209</td><td>36.2</td><td>127</td><td>48.9</td><td>104</td><td>172</td><td>33.3</td><td>94.0</td></tr><tr><td>HB vs RW</td><td>6.3</td><td>20.3</td><td>3.7</td><td>15.3</td><td>7.2</td><td>10.9</td><td>15.6</td><td>3.1</td><td>9.96</td></tr></tbody></table><figcaption><span><span>Table 2</span>: </span><span>Relative efficiency (defined as ESS/time) of GB, LB and HB compared to RW . The table reports the value for the first 8 regions and the average over all 20 regions.</span></figcaption></figure>",
        "html_table": "<table><thead><tr><th>Region</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>Average</th></tr></thead><tbody><tr><td>GB vs RW</td><td>0.8</td><td>2.9</td><td>0.7</td><td>1.7</td><td>1.4</td><td>0.5</td><td>1.0</td><td>0.9</td><td>0.94</td></tr><tr><td>LB vs RW</td><td>60.6</td><td>209</td><td>36.2</td><td>127</td><td>48.9</td><td>104</td><td>172</td><td>33.3</td><td>94.0</td></tr><tr><td>HB vs RW</td><td>6.3</td><td>20.3</td><td>3.7</td><td>15.3</td><td>7.2</td><td>10.9</td><td>15.6</td><td>3.1</td><td>9.96</td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th>Region</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>Average</th></tr></thead><tbody><tr><td>GB vs RW</td><td>0.8</td><td>2.9</td><td>0.7</td><td>1.7</td><td>1.4</td><td>0.5</td><td>1.0</td><td>0.9</td><td>0.94</td></tr><tr><td>LB vs RW</td><td>60.6</td><td>209</td><td>36.2</td><td>127</td><td>48.9</td><td>104</td><td>172</td><td>33.3</td><td>94.0</td></tr><tr><td>HB vs RW</td><td>6.3</td><td>20.3</td><td>3.7</td><td>15.3</td><td>7.2</td><td>10.9</td><td>15.6</td><td>3.1</td><td>9.96</td></tr></tbody></table>",
        "citations": [
            "To provide a quantitative comparison between the performances of the four schemes, we consider as efficiency measure the effective sample sizes per unit of computation time relative to RW. Effective sample sizes are computed using the coda R package [Plummer etal., 2006] and averaged over 5 summary statistics (each summary statistics being the Hamming distance from a matching randomly drawn from the posterior). From Table 2 we can see that LB provides roughly two orders of magnitude improvement in efficiency over RW and GB and one order of magnitude improvement over HB."
        ],
        "caption": "Table 2: Relative efficiency (defined as ESS/time) of GB, LB and HB compared to RW . The table reports the value for the first 8 regions and the average over all 20 regions."
    },
    "2111.01767_2": {
        "table": "<table><thead><tr><th><span>Methods</span></th><th><span>naive</span></th><th><span>EM</span></th><th><span>EML</span></th></tr></thead><tbody><tr><th><math><semantics><msub><mrow><mo></mo><mrow><msup><mtext>Corr</mtext><mtext>est</mtext></msup><mo></mo><msup><mtext>Corr</mtext><mo></mo></msup></mrow><mo></mo></mrow><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><apply><csymbol>delimited-</csymbol><apply><minus></minus><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><ci><mtext>est</mtext></ci></apply><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><times></times></apply></apply></apply><ci></ci></apply></annotation-xml><annotation>\\lVert\\text{Corr}^{\\text{est}}-\\text{Corr}^{*}\\rVert_{F}</annotation></semantics></math></th><td>0.76</td><td>1.97</td><td>0.34</td></tr><tr><th>standard error</th><td>0.0012</td><td>0.0111</td><td>0.0010</td></tr></tbody></table>",
        "html_table": "<table><thead><tr><th><span>Methods</span></th><th><span>naive</span></th><th><span>EM</span></th><th><span>EML</span></th></tr></thead><tbody><tr><th><math><semantics><msub><mrow><mo></mo><mrow><msup><mtext>Corr</mtext><mtext>est</mtext></msup><mo></mo><msup><mtext>Corr</mtext><mo></mo></msup></mrow><mo></mo></mrow><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><apply><csymbol>delimited-</csymbol><apply><minus></minus><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><ci><mtext>est</mtext></ci></apply><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><times></times></apply></apply></apply><ci></ci></apply></annotation-xml><annotation>\\lVert\\text{Corr}^{\\text{est}}-\\text{Corr}^{*}\\rVert_{F}</annotation></semantics></math></th><td>0.76</td><td>1.97</td><td>0.34</td></tr><tr><th>standard error</th><td>0.0012</td><td>0.0111</td><td>0.0010</td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th><span>Methods</span></th><th><span>naive</span></th><th><span>EM</span></th><th><span>EML</span></th></tr></thead><tbody><tr><th><math><semantics><msub><mrow><mo></mo><mrow><msup><mtext>Corr</mtext><mtext>est</mtext></msup><mo></mo><msup><mtext>Corr</mtext><mo></mo></msup></mrow><mo></mo></mrow><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><apply><csymbol>delimited-</csymbol><apply><minus></minus><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><ci><mtext>est</mtext></ci></apply><apply><csymbol>superscript</csymbol><ci><mtext>Corr</mtext></ci><times></times></apply></apply></apply><ci></ci></apply></annotation-xml><annotation>\\lVert\\text{Corr}^{\\text{est}}-\\text{Corr}^{*}\\rVert_{F}</annotation></semantics></math></th><td>0.76</td><td>1.97</td><td>0.34</td></tr><tr><th>standard error</th><td>0.0012</td><td>0.0111</td><td>0.0010</td></tr></tbody></table>",
        "citations": [
            "Local shuffling prior. As shown in the Table 2, the EM approach with local shuffling prior achieves significant error reductions compared to the naive approach and the EM approach without regularization."
        ],
        "caption": "Table 2: Results of the real data experiment (Beijing Air Quality Data) with local shuffling permutation. Each number in the table is the average REE over 100 replications.",
        "processed": true
    },
    "2004.02008_4": {
        "table": "<table><thead><tr><th></th><th colspan=\"2\"><span>SDS</span></th><th colspan=\"2\"><span>SIPP</span></th></tr><tr><th><span>Model</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th></tr></thead><tbody><tr><th><span>DP</span></th><td><span>0.03</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>PY</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>ESCNB</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.01</span></td><td><span>0.02</span></td></tr><tr><th><span>ESCD</span></th><td><span>0.02</span></td><td><span>0.02</span></td><td><span>0.01</span></td><td><span>0.01</span></td></tr></tbody></table>",
        "html_table": "<table><thead><tr><th></th><th colspan=\"2\"><span>SDS</span></th><th colspan=\"2\"><span>SIPP</span></th></tr><tr><th><span>Model</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th></tr></thead><tbody><tr><th><span>DP</span></th><td><span>0.03</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>PY</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>ESCNB</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.01</span></td><td><span>0.02</span></td></tr><tr><th><span>ESCD</span></th><td><span>0.02</span></td><td><span>0.02</span></td><td><span>0.01</span></td><td><span>0.01</span></td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th></th><th colspan=\"2\"><span>SDS</span></th><th colspan=\"2\"><span>SIPP</span></th></tr><tr><th><span>Model</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th><th><span>FNR SE</span></th><th><span>FDR SE</span></th></tr></thead><tbody><tr><th><span>DP</span></th><td><span>0.03</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>PY</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.02</span></td><td><span>0.01</span></td></tr><tr><th><span>ESCNB</span></th><td><span>0.02</span></td><td><span>0.04</span></td><td><span>0.01</span></td><td><span>0.02</span></td></tr><tr><th><span>ESCD</span></th><td><span>0.02</span></td><td><span>0.02</span></td><td><span>0.01</span></td><td><span>0.01</span></td></tr></tbody></table>",
        "citations": [
            "Figures 5 and 6 show the traceplots for K, FNR and FDR for the four chains used for the SDS and SIPP data sets, respectively. No issues of convergence are observed in either case. However, the mixing of the chains for the SDS is slower compared to the SIPP data. Table 4 displays the estimated MCMC standard errors for the estimation of the average posterior FNR and FDR using the four chains and discarding the first 5,000 iterations of each run as a burn-in. The MCMC standard errors were computed using the function summary.mcmc from the R package CODA (Plummer etal. 2006). The estimated standard errors are all between 0.01%percent0.010.01\\% and 0.04%percent0.040.04\\%, indicating that the FNR and FDR estimates presented in Section 5.3 of the main document are reliable up to one decimal place (in percentage), which is the level of precision reported in Tables 2 and 3 of the main document."
        ],
        "caption": "Table 4: Time-series MCMC error (in percentages) for the posterior expected values of FNR and FDR for SDS and SIPP data sets.",
        "processed": true
    },
    "2209.07569_6": {
        "table": "<div><span><table><tr><td><span>Dataset</span></td><td><span>Model</span></td><td><math><semantics><mi>P</mi><annotation-xml><ci></ci></annotation-xml><annotation>P</annotation></semantics></math></td><td><math><semantics><mi>R</mi><annotation-xml><ci></ci></annotation-xml><annotation>R</annotation></semantics></math></td><td><math><semantics><mi>F</mi><annotation-xml><ci></ci></annotation-xml><annotation>F</annotation></semantics></math></td><td><math><semantics><mrow><mi>A</mi><mo></mo><mi>c</mi><mo></mo><mi>c</mi></mrow><annotation-xml><apply><times></times><ci></ci><ci></ci><ci></ci></apply></annotation-xml><annotation>Acc</annotation></semantics></math></td><td><math><semantics><msub><mi>E</mi><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><ci></ci><ci></ci></apply></annotation-xml><annotation>E_{F}</annotation></semantics></math></td></tr><tr><td rowspan=\"2\"><span><span><span><span>AmazonMI</span></span></span></span></td><td>In-parallel</td><td><span>.829</span></td><td><span>.991</span></td><td><span>.901</span></td><td><span>.960</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.921</span></td><td><span>.905</span></td><td><span>.912</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.933</span></td><td><span>.985</span></td><td><span>.958</span></td><td><span>.985</span></td><td><span>57.6 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>Walmart-</span></span><span><span>Amazon</span></span></span></span></td><td>In-parallel</td><td><span>.852</span></td><td><span>.812</span></td><td><span>.831</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.854</span></td><td><span>.772</span></td><td><span>.810</span></td><td><span>.966</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.903</span></td><td><span>.792</span></td><td><span>.844</span></td><td><span>.985</span></td><td><span>7.7 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>WDC</span></span></span></span></td><td>In-parallel</td><td><span>.786</span></td><td><span>.745</span></td><td><span>.761</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.808</span></td><td><span>.713</span></td><td><span>.757</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.775</span></td><td><span>.788</span></td><td><span>.782</span></td><td><span>.950</span></td><td><span>8.8 %</span></td></tr></table></span></div></figure>",
        "html_table": "<div><span><table><tr><td><span>Dataset</span></td><td><span>Model</span></td><td><math><semantics><mi>P</mi><annotation-xml><ci></ci></annotation-xml><annotation>P</annotation></semantics></math></td><td><math><semantics><mi>R</mi><annotation-xml><ci></ci></annotation-xml><annotation>R</annotation></semantics></math></td><td><math><semantics><mi>F</mi><annotation-xml><ci></ci></annotation-xml><annotation>F</annotation></semantics></math></td><td><math><semantics><mrow><mi>A</mi><mo></mo><mi>c</mi><mo></mo><mi>c</mi></mrow><annotation-xml><apply><times></times><ci></ci><ci></ci><ci></ci></apply></annotation-xml><annotation>Acc</annotation></semantics></math></td><td><math><semantics><msub><mi>E</mi><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><ci></ci><ci></ci></apply></annotation-xml><annotation>E_{F}</annotation></semantics></math></td></tr><tr><td rowspan=\"2\"><span><span><span><span>AmazonMI</span></span></span></span></td><td>In-parallel</td><td><span>.829</span></td><td><span>.991</span></td><td><span>.901</span></td><td><span>.960</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.921</span></td><td><span>.905</span></td><td><span>.912</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.933</span></td><td><span>.985</span></td><td><span>.958</span></td><td><span>.985</span></td><td><span>57.6 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>Walmart-</span></span><span><span>Amazon</span></span></span></span></td><td>In-parallel</td><td><span>.852</span></td><td><span>.812</span></td><td><span>.831</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.854</span></td><td><span>.772</span></td><td><span>.810</span></td><td><span>.966</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.903</span></td><td><span>.792</span></td><td><span>.844</span></td><td><span>.985</span></td><td><span>7.7 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>WDC</span></span></span></span></td><td>In-parallel</td><td><span>.786</span></td><td><span>.745</span></td><td><span>.761</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.808</span></td><td><span>.713</span></td><td><span>.757</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.775</span></td><td><span>.788</span></td><td><span>.782</span></td><td><span>.950</span></td><td><span>8.8 %</span></td></tr></table></span></div></figure>",
        "table_head": "<div><span><table><tr><td><span>Dataset</span></td><td><span>Model</span></td><td><math><semantics><mi>P</mi><annotation-xml><ci></ci></annotation-xml><annotation>P</annotation></semantics></math></td><td><math><semantics><mi>R</mi><annotation-xml><ci></ci></annotation-xml><annotation>R</annotation></semantics></math></td><td><math><semantics><mi>F</mi><annotation-xml><ci></ci></annotation-xml><annotation>F</annotation></semantics></math></td><td><math><semantics><mrow><mi>A</mi><mo></mo><mi>c</mi><mo></mo><mi>c</mi></mrow><annotation-xml><apply><times></times><ci></ci><ci></ci><ci></ci></apply></annotation-xml><annotation>Acc</annotation></semantics></math></td><td><math><semantics><msub><mi>E</mi><mi>F</mi></msub><annotation-xml><apply><csymbol>subscript</csymbol><ci></ci><ci></ci></apply></annotation-xml><annotation>E_{F}</annotation></semantics></math></td></tr><tr><td rowspan=\"2\"><span><span><span><span>AmazonMI</span></span></span></span></td><td>In-parallel</td><td><span>.829</span></td><td><span>.991</span></td><td><span>.901</span></td><td><span>.960</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.921</span></td><td><span>.905</span></td><td><span>.912</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.933</span></td><td><span>.985</span></td><td><span>.958</span></td><td><span>.985</span></td><td><span>57.6 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>Walmart-</span></span><span><span>Amazon</span></span></span></span></td><td>In-parallel</td><td><span>.852</span></td><td><span>.812</span></td><td><span>.831</span></td><td><span>.969</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.854</span></td><td><span>.772</span></td><td><span>.810</span></td><td><span>.966</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.903</span></td><td><span>.792</span></td><td><span>.844</span></td><td><span>.985</span></td><td><span>7.7 %</span></td></tr><tr><td rowspan=\"2\"><span><span><span><span>WDC</span></span></span></span></td><td>In-parallel</td><td><span>.786</span></td><td><span>.745</span></td><td><span>.761</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td>Multi-label</td><td><span>.808</span></td><td><span>.713</span></td><td><span>.757</span></td><td><span>.948</span></td><td><span>-</span></td></tr><tr><td><span>\\cdashline</span>2-7</td><td><span>FlexER</span></td><td><span>.775</span></td><td><span>.788</span></td><td><span>.782</span></td><td><span>.950</span></td><td><span>8.8 %</span></td></tr></table></span></div></figure>",
        "citations": [
            "Table6 provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation.",
            "Table7 provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6). We compare FlexER with the same baselines as in Section5.4.1 for each single intent."
        ],
        "caption": "Table 6. Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}.",
        "processed": true
    },
    "2205.10678_1": {
            "table": "<table><thead><tr><th><span><span>Method</span></span></th><th><span><span>all (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>all (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th></tr></thead><tbody><tr><td><span><span>XGBoost</span></span></td><td><span><span>0.934</span></span></td><td><span><span>0.779</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.997</span></span></td><td><span><span>0.71</span></span></td><td><span><span>0.49</span></span></td></tr><tr><td><span><span>XGBoost + top all</span></span></td><td><span><span>0.949</span></span></td><td><span><span>0.9</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.989</span></span></td><td><span><span>0.896</span></span></td><td><span><span>0.695</span></span></td></tr><tr><td><span><span>Cascade 4 + top all</span></span></td><td><span><span>0.945</span></span></td><td><span><span>0.918</span></span></td><td><span><span>NA</span></span></td><td><span><span>1.0</span></span></td><td><span><span>0.906</span></span></td><td><span><span>0.834</span></span></td></tr><tr><td><span><span>Chain + top all</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.905</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.816</span></span></td></tr></tbody></table>",
            "html_table": "<table><thead><tr><th><span><span>Method</span></span></th><th><span><span>all (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>all (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th></tr></thead><tbody><tr><td><span><span>XGBoost</span></span></td><td><span><span>0.934</span></span></td><td><span><span>0.779</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.997</span></span></td><td><span><span>0.71</span></span></td><td><span><span>0.49</span></span></td></tr><tr><td><span><span>XGBoost + top all</span></span></td><td><span><span>0.949</span></span></td><td><span><span>0.9</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.989</span></span></td><td><span><span>0.896</span></span></td><td><span><span>0.695</span></span></td></tr><tr><td><span><span>Cascade 4 + top all</span></span></td><td><span><span>0.945</span></span></td><td><span><span>0.918</span></span></td><td><span><span>NA</span></span></td><td><span><span>1.0</span></span></td><td><span><span>0.906</span></span></td><td><span><span>0.834</span></span></td></tr><tr><td><span><span>Chain + top all</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.905</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.816</span></span></td></tr></tbody></table>",
            "table_head": "<table><thead><tr><th><span><span>Method</span></span></th><th><span><span>all (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>all (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>with ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>95</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>95</cn></apply></annotation-xml><annotation>95\\%</annotation></semantics></math>)</span></span></th><th><span><span>without ID (<math><semantics><mrow><mn>99</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99</cn></apply></annotation-xml><annotation>99\\%</annotation></semantics></math>)</span></span></th></tr></thead><tbody><tr><td><span><span>XGBoost</span></span></td><td><span><span>0.934</span></span></td><td><span><span>0.779</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.997</span></span></td><td><span><span>0.71</span></span></td><td><span><span>0.49</span></span></td></tr><tr><td><span><span>XGBoost + top all</span></span></td><td><span><span>0.949</span></span></td><td><span><span>0.9</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.989</span></span></td><td><span><span>0.896</span></span></td><td><span><span>0.695</span></span></td></tr><tr><td><span><span>Cascade 4 + top all</span></span></td><td><span><span>0.945</span></span></td><td><span><span>0.918</span></span></td><td><span><span>NA</span></span></td><td><span><span>1.0</span></span></td><td><span><span>0.906</span></span></td><td><span><span>0.834</span></span></td></tr><tr><td><span><span>Chain + top all</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.905</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>NA</span></span></td><td><span><span>0.816</span></span></td></tr></tbody></table>",
            "citations": [
                "To get better insight on the methods performance we provide separate figures for cases which do not contain ID in the title (FIG.4) and for the cases with ID in title (FIG.4). Detailed scores for two critical precision thresholds are summarized in TAB.1."
            ],
            "caption": "Table 1: Mean recall for best model in each category at 95% and 99% precision",
            "processed": true
    },
    "2211.02161_4": {
        "html_table": "<table><thead><tr><th><span>Method</span></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>ACM-C</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>ACM-D</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>Scholar-C</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>Scholar-D</span></td></tr></table></th><th><table><tr><td><span>iTune-</span></td></tr><tr><td><span>Amazon</span></td></tr></table></th><th><table><tr><td><span>Music-</span></td></tr><tr><td><span>Brainz</span></td></tr></table></th><th><table><tr><td><span>Amazon-</span></td></tr><tr><td><span>Google</span></td></tr></table></th><th><span>NCVR</span></th><th><table><tr><td><span>European</span></td></tr><tr><td><span>Census</span></td></tr></table></th></tr></thead><tbody><tr><th><span>BF</span><cite><span>[</span><a>45</a>, <a>46</a>, <a>10</a><span>]</span></cite></th><td><span>6</span></td><td><span>6</span></td><td><span>70</span></td><td><span>71</span></td><td><span>91</span></td><td><span>16</span></td><td><span>11</span></td><td><span>462</span></td><td><span>58</span></td></tr><tr><th><span>DP-BF</span><cite><span>[</span><a>18</a>, <a>19</a>, <a>7</a><span>]</span></cite></th><td><span>8</span></td><td><span>9</span></td><td><span>75</span></td><td><span>75</span></td><td><span>94</span></td><td><span>18</span></td><td><span>13</span></td><td><span>473</span></td><td><span>73</span></td></tr><tr><th><span>DL-BF</span></th><td><span>8</span></td><td><span>9</span></td><td><span>77</span></td><td><span>78</span></td><td><span>96</span></td><td><span>18</span></td><td><span>14</span></td><td><span>475</span></td><td><span>75</span></td></tr><tr><th><span>DP-DL-BF</span></th><td><span>10</span></td><td><span>12</span></td><td><span>92</span></td><td><span>91</span></td><td><span>103</span></td><td><span>25</span></td><td><span>19</span></td><td><span>491</span></td><td><span>82</span></td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th><span>Method</span></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>ACM-C</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>ACM-D</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>Scholar-C</span></td></tr></table></th><th><table><tr><td><span>DBLP-</span></td></tr><tr><td><span>Scholar-D</span></td></tr></table></th><th><table><tr><td><span>iTune-</span></td></tr><tr><td><span>Amazon</span></td></tr></table></th><th><table><tr><td><span>Music-</span></td></tr><tr><td><span>Brainz</span></td></tr></table></th><th><table><tr><td><span>Amazon-</span></td></tr><tr><td><span>Google</span></td></tr></table></th><th><span>NCVR</span></th><th><table><tr><td><span>European</span></td></tr><tr><td><span>Census</span></td></tr></table></th></tr></thead><tbody><tr><th><span>BF</span><cite><span>[</span><a>45</a>, <a>46</a>, <a>10</a><span>]</span></cite></th><td><span>6</span></td><td><span>6</span></td><td><span>70</span></td><td><span>71</span></td><td><span>91</span></td><td><span>16</span></td><td><span>11</span></td><td><span>462</span></td><td><span>58</span></td></tr></tbody></table>",
        "citations": [
            "TableIV shows the runtime of all approaches on different data sets. As expected, our approach consumes more runtime compared to other approaches because of the addition of differentially private noise in BFs and the independent training of the local models by each DO. DP-BF and DL-BF need a similar runtime due to the independent noise addition and local model training by each DO, respectively, as classification of unlabelled record pairs by the LU requires a small amount of additional runtime for feature generation for the record pairs generated by the blocking technique. Thus, the use of an efficient blocking technique can reduce the additional overhead of runtime required by the LU to a minimum."
        ],
        "caption": "TABLE IV: Average runtime results (in seconds) for linking the different data sets."
    },
    "2106.14444_1": {
        "table": "<table><tbody><tr><th></th><th>Sub-task 1</th><th>Sub-task 2</th><th colspan=\"3\">Sub-task 3</th><th rowspan=\"2\"><span>Accuracy</span></th><th rowspan=\"2\"><span>Appropriateness</span></th></tr><tr><td></td><td>F1</td><td>R@1</td><td>BLEU-1</td><td>METEOR</td><td>Rouge-L</td></tr><tr><th>Baseline</th><th>0.9455</th><th>0.6201</th><th>0.3031</th><th>0.2983</th><th>0.3039</th><th>3.7155</th><th>3.9386</th></tr><tr><td>Our system</td><td><span>0.9675</span></td><td><span>0.8702</span></td><td><span>0.3743</span></td><td><span>0.3854</span></td><td><span>0.3797</span></td><td><span>4.2722</span></td><td><span>4.2619</span></td></tr></tbody></table>",
        "html_table": "<table><tbody><tr><th></th><th>Sub-task 1</th><th>Sub-task 2</th><th colspan=\"3\">Sub-task 3</th><th rowspan=\"2\"><span>Accuracy</span></th><th rowspan=\"2\"><span>Appropriateness</span></th></tr><tr><td></td><td>F1</td><td>R@1</td><td>BLEU-1</td><td>METEOR</td><td>Rouge-L</td></tr><tr><th>Baseline</th><th>0.9455</th><th>0.6201</th><th>0.3031</th><th>0.2983</th><th>0.3039</th><th>3.7155</th><th>3.9386</th></tr><tr><td>Our system</td><td><span>0.9675</span></td><td><span>0.8702</span></td><td><span>0.3743</span></td><td><span>0.3854</span></td><td><span>0.3797</span></td><td><span>4.2722</span></td><td><span>4.2619</span></td></tr></tbody></table>",
        "table_head": "<table><tbody><tr><th></th><th>Sub-task 1</th><th>Sub-task 2</th><th colspan=\"3\">Sub-task 3</th><th rowspan=\"2\"><span>Accuracy</span></th><th rowspan=\"2\"><span>Appropriateness</span></th></tr><tr><td></td><td>F1</td><td>R@1</td><td>BLEU-1</td><td>METEOR</td><td>Rouge-L</td></tr><tr><th>Baseline</th><th>0.9455</th><th>0.6201</th><th>0.3031</th><th>0.2983</th><th>0.3039</th><th>3.7155</th><th>3.9386</th></tr><tr><td>Our system</td><td><span>0.9675</span></td><td><span>0.8702</span></td><td><span>0.3743</span></td><td><span>0.3854</span></td><td><span>0.3797</span></td><td><span>4.2722</span></td><td><span>4.2619</span></td></tr></tbody></table>",
        "citations": [
            "The overview of DSTC9 (Gunasekara etal. 2020) reports the performance of our system (Team 11) at various stages of the pipeline, as summarized in Table1. Here we also assess our methods in individual sub-tasks separately, decoupling the results on downstream tasks from upstream tasks.",
            "Our final system consists of only T5 models, fine-tuned on different sub-tasks. Table1 shows the overall effectiveness of our system compared to the baseline system. Our system made significant improvements in all sub-tasks and consequently is able to produce response of higher quality, in terms of accuracy and appropriateness according to human evaluation."
        ],
        "caption": "Table 1: Overall performance of our system (Team 11) compared to the baseline, as reported in the overview of DSTC9 (Gunasekara etal. 2020). The accuracy and appropriateness of the system response were evaluated by human on a scale of 1-5. Note that the scores for the downstream sub-tasks are weighted by the performance of the upstream tasks.",
        "processed": true
    },
    "1704.02450_3": {
        "table": "<table><tbody><tr><td>Method</td><td>Rank-1(%)</td><td>FAR=1%(%)</td></tr><tr><td>Original WLD</td><td>74.34</td><td>-</td></tr><tr><td>SIFT</td><td>76.28</td><td>-</td></tr><tr><td>EUCLBP</td><td>79.36</td><td>-</td></tr><tr><td>LFDA</td><td>81.43</td><td>-</td></tr><tr><td>MCWLD</td><td>84.24</td><td>-</td></tr><tr><td>VGG</td><td>80.89</td><td>72.08</td></tr><tr><td>CenterLoss</td><td>84.07</td><td>76.20</td></tr><tr><td>Light CNN</td><td>84.07</td><td>75.30</td></tr><tr><td>CDL</td><td><span>85.35</span></td><td><span>82.52</span></td></tr></tbody></table>",
        "html_table": "<table><tbody><tr><td>Method</td><td>Rank-1(%)</td><td>FAR=1%(%)</td></tr><tr><td>Original WLD</td><td>74.34</td><td>-</td></tr><tr><td>SIFT</td><td>76.28</td><td>-</td></tr><tr><td>EUCLBP</td><td>79.36</td><td>-</td></tr><tr><td>LFDA</td><td>81.43</td><td>-</td></tr><tr><td>MCWLD</td><td>84.24</td><td>-</td></tr><tr><td>VGG</td><td>80.89</td><td>72.08</td></tr><tr><td>CenterLoss</td><td>84.07</td><td>76.20</td></tr><tr><td>Light CNN</td><td>84.07</td><td>75.30</td></tr><tr><td>CDL</td><td><span>85.35</span></td><td><span>82.52</span></td></tr></tbody></table>",
        "table_head": "<table><tbody><tr><td>Method</td><td>Rank-1(%)</td><td>FAR=1%(%)</td></tr><tr><td>Original WLD</td><td>74.34</td><td>-</td></tr><tr><td>SIFT</td><td>76.28</td><td>-</td></tr><tr><td>EUCLBP</td><td>79.36</td><td>-</td></tr><tr><td>LFDA</td><td>81.43</td><td>-</td></tr><tr><td>MCWLD</td><td>84.24</td><td>-</td></tr><tr><td>VGG</td><td>80.89</td><td>72.08</td></tr><tr><td>CenterLoss</td><td>84.07</td><td>76.20</td></tr><tr><td>Light CNN</td><td>84.07</td><td>75.30</td></tr><tr><td>CDL</td><td><span>85.35</span></td><td><span>82.52</span></td></tr></tbody></table>",
            "citations": [
                "We also evaluate CDL on the viewed sketch-photo face recognition database. As is shown in Table 3, CDL obtains 85.35% rank-1 accuracy which outperforms other viewed sketch-photo methods on the IIIT-D Sketch Database. Note that we employ CUFSF as the training dataset on different CNN-based methods. Table 3 shows the performance of VGG, CenterLoss, Lightened CNN and CDL on the IIIT-D Sketch Database. It is obvious that the proposed CDL is better than other CNN-based methods on a small number of training samples. Besides, if there are more sketch-photo images (not only two images in each identities), the performance of CDL will be further improved."
            ],
            "caption": "Table 3: The comparison of rank-1 and VR@FAR=1% for the IIIT-D Sketch Database.",
            "processed": true
    },
    "1305.2254_6": {
        "html_table": "<table><thead><tr><th></th><th>Cites</th><th>Authors</th><th>Venues</th><th>Titles</th></tr></thead><tbody><tr><th>MLN(Fig<a><span>1</span></a>)</th><td>0.513</td><td>0.532</td><td>0.602</td><td>0.544</td></tr><tr><th>MLN(S&amp;D)</th><td>0.520</td><td>0.573</td><td>0.627</td><td>0.629</td></tr><tr><th>ProPPR(<span>w</span>=1)</th><td>0.680</td><td>0.836</td><td>0.860</td><td><span>0.908</span></td></tr><tr><th>ProPPR</th><td><span>0.800</span></td><td><span>0.840</span></td><td><span>0.869</span></td><td>0.900</td></tr></tbody></table>",
        "table_head":"<table><thead><tr><th></th><th>Cites</th><th>Authors</th><th>Venues</th><th>Titles</th></tr></thead><tbody><tr><th>MLN(Fig<a><span>1</span></a>)</th><td>0.513</td><td>0.532</td><td>0.602</td><td>0.544</td></tr>",
        "citations": [
            "The results in Table6 all use the same data and evaluation procedure, and the MLNs were trained with the state-of-the-art Alchemy system using the recommended commands for this data (which is distributed with Alchemy999http://alchemy.cs.washington.edu). However, we should note that the MLN results reproduced here are not identical to previous-reported ones [15]. Singla and Domingos used a number of complex heuristics that are difficult to reproducee.g., one of these was combining MLNs with a heuristic, TFIDF-based matching procedure based on canopies [9]. While the trained ProPPR model outperformed the reproduced MLN model in all prediction tasks, it outperforms the reported results from Singla and Domingos only on venue, and does less well than the reported results on citation and author101010Performance on title matching is not reported by Singla and Domingos.."
        ],
        "caption": "Table 6: AUC results on CORA citation-matching.",
        "footnotes": [""]
    },
    "2005.09399_9": {
            "html_table": "<table><tbody><tr><td></td><td><span>airports</span></td><td><span>airlines</span></td><td><span>twitter</span></td><td><span>books</span></td><td colspan=\"2\"><span>iati</span></td><td><span>www2012</span></td></tr><tr><td><span>link</span></td><td><span>umbel:isLike</span></td><td><span>umbel:isLike</span></td><td><span>dct:subject</span></td><td><span>dct:subject</span></td><td><span>dct:subject</span></td><td><span>dct:coverage</span></td><td><span>foaf:based_near</span></td></tr><tr><td><span>Recall of token blocking</span></td><td><math><semantics><mrow><mn>97.47</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>97.47</cn></apply></annotation-xml><annotation>97.47\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>99.75</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>99.75</cn></apply></annotation-xml><annotation>99.75\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>9.52</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>9.52</cn></apply></annotation-xml><annotation>9.52\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>63.55</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>63.55</cn></apply></annotation-xml><annotation>63.55\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>49.13</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>49.13</cn></apply></annotation-xml><annotation>49.13\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>39.46</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>39.46</cn></apply></annotation-xml><annotation>39.46\\%</annotation></semantics></math></td><td><math><semantics><mrow><mn>62.61</mn><mo>%</mo></mrow><annotation-xml><apply><csymbol>percent</csymbol><cn>62.61</cn></apply></annotation-xml><annotation>62.61\\%</annotation></semantics></math></td></tr></tbody></table>",
            "table_head": "<table><tbody><tr><td></td><td><span>airports</span></td><td><span>airlines</span></td><td><span>twitter</span></td><td><span>books</span></td><td colspan=\"2\"><span>iati</span></td><td><span>www2012</span></td></tr><tr><td><span>link</span></td><td><span>umbel:isLike</span></td><td><span>umbel:isLike</span></td><td><span>dct:subject</span></td><td><span>dct:subject</span></td><td><span>dct:subject</span></td><td><span>dct:coverage</span></td><td><span>foaf:based_near</span></td></tr>",
            "citations": [
                "In order to evaluate the ability of blocking methods to identify more types of links, semantically close or even not that close to equivalence links, we have run a set of experiments with the peripheral collections consisting of each of the datasets of TableIII and BTC12DBpedia. We have chosen a wide range of link types, in order to show that the same blocking method can better identify some specific link types, and fail to identify other link types. TableIX provides the recall of token blocking, when applied to each of those collections. Similarly to the owl:sameAs links, token blocking performs well for links with the semantics of equivalence (i.e., umbel:isLike, expressing a possible equivalence), as in the airports and airlines datasets with recall values close to 100%percent100100\\%. It also manages to identify many subject associations (i.e., dct:subject, expressing the topic of a description), as in the cases of books and iati datasets. It performs poorly in identifying this kind of association, however, in the twitter dataset, where its recall values fall to below 10%percent1010\\%. This could be justified by the nature of this dataset, which, in most cases, simply states who created a slideset. Regarding spatial associations (i.e., dct:coverage, expressing the spatial topic of a description, and foaf:based_near, relating two spatial objects), token blocking manages to identify a mere 39%percent3939\\% of the coverage associations of the iati dataset, but it performs much better in identifying the based_near associations of www2012, with a recall of 63%percent6363\\%. The spatial relationships of coverage are looser than those of based_near, hence the related entities are not so strongly related in the former type of links. For example, in iati, the description of a project regarding the evaluation of cereal crop residues is linked to the DBpedia resource describing Latin America and the Caribbean, through the coverage relation, while, in www2012, a Greek professor is linked to the DBpedia resource describing Greece, through the based_near relation.",
                "Finally, in peripheral collections, there are several types of relations, other than equivalence, between descriptions. Token blocking identifies some of them, depending on the dataset, the specific type of such links, and the immediacy of those relations (TableIX). It does not perform well when the data do not contain much information (e.g., see the characteristics of twitter in TableIII), or when the relationship of the entities is loose (e.g., see the recall of iati for dct:coverage in TableIX). Thus, for a quantitative evaluation of blocking methods ground truth should not be restricted only to owl:sameAs links. We could potentially take other relations into account, to identify more such links, or more owl:sameAs links, using iterative algorithms."
            ],
            "caption": "TABLE IX: Recall of the collections composed of datasets of TableIII and BTC12DBpedia.",
            "footnotes": [""]
    },
    "2003.04238_8": {
        "table": "<table><thead><tr><th>Method</th><th>Specification</th><th>Parameters</th><th>TPR (est. TPR)</th><th>PPV (est. PPV)</th></tr></thead><tbody><tr><td>Bayesian</td><td>baseline</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.204 (0.326)</td><td>0.768 (0.756)</td></tr><tr><td>-</td><td>common names</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.223 (0.361)</td><td>0.763 (0.773)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.455 (0.389)</td><td>0.657 (0.824)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>4</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>2</cn><cn>4</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,2,4)</annotation></semantics></math></td><td>0.359 (0.301)</td><td>0.746 (0.922)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>6</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>3</cn><cn>6</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,3,6)</annotation></semantics></math></td><td>0.315 (0.263)</td><td>0.770 (0.949)</td></tr></tbody></table>",
        "html_table": "<table><thead><tr><th>Method</th><th>Specification</th><th>Parameters</th><th>TPR (est. TPR)</th><th>PPV (est. PPV)</th></tr></thead><tbody><tr><td>Bayesian</td><td>baseline</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.204 (0.326)</td><td>0.768 (0.756)</td></tr><tr><td>-</td><td>common names</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.223 (0.361)</td><td>0.763 (0.773)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.455 (0.389)</td><td>0.657 (0.824)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>4</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>2</cn><cn>4</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,2,4)</annotation></semantics></math></td><td>0.359 (0.301)</td><td>0.746 (0.922)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>6</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>3</cn><cn>6</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,3,6)</annotation></semantics></math></td><td>0.315 (0.263)</td><td>0.770 (0.949)</td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th>Method</th><th>Specification</th><th>Parameters</th><th>TPR (est. TPR)</th><th>PPV (est. PPV)</th></tr></thead><tbody><tr><td>Bayesian</td><td>baseline</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.204 (0.326)</td><td>0.768 (0.756)</td></tr><tr><td>-</td><td>common names</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.223 (0.361)</td><td>0.763 (0.773)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>1</cn><cn>2</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,1,2)</annotation></semantics></math></td><td>0.455 (0.389)</td><td>0.657 (0.824)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>4</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>2</cn><cn>4</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,2,4)</annotation></semantics></math></td><td>0.359 (0.301)</td><td>0.746 (0.922)</td></tr><tr><td>-</td><td>record-specific</td><td><math><semantics><mrow><mi></mi><mo>=</mo><mrow><mo>(</mo><mn>1</mn><mo>,</mo><mn>3</mn><mo>,</mo><mn>6</mn><mo>)</mo></mrow></mrow><annotation-xml><apply><eq></eq><ci></ci><vector><cn>1</cn><cn>3</cn><cn>6</cn></vector></apply></annotation-xml><annotation>\\lambda=(1,3,6)</annotation></semantics></math></td><td>0.315 (0.263)</td><td>0.770 (0.949)</td></tr></tbody></table>",
            "citations": [
                "The above measures of TPR and PPV are true in the sense that they are drawn from expert-linked matches available for the Union Army dataset. TPR and PPV can also be estimated within the model when true matches are unavailable, as discussed in Section 3.5. Estimated rates for our specifications are listed in Table 8. Estimated TPR and PPV were available for fastLink matchings but we found they were unreliable in settings where nA<<nBmuch-less-thansubscriptsubscriptn_{A}<<n_{B}."
            ],
            "caption": "Table 8: Actual against estimated TPR and PPV for selected specifications.",
            "processed": true
    },
    "1906.08042_5": {
        "html_table": "<table><tbody><tr><th>Method</th><td>Prec</td><td>Recall</td><td>F1</td></tr><tr><th>Train on Src</th><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><mn>6.37</mn><annotation-xml><cn>6.37</cn></annotation-xml><annotation>6.37</annotation></semantics></math></td><td><math><semantics><msub><mn>11.76</mn><mrow><mo></mo><mn>6.84</mn></mrow></msub><annotation-xml><apply><csymbol>subscript</csymbol><cn>11.76</cn><apply><csymbol>plus-or-minus</csymbol><cn>6.84</cn></apply></apply></annotation-xml><annotation>11.76_{\\pm 6.84}</annotation></semantics></math></td></tr><tr><th>+Adaptation</th><td><math><semantics><mn>95.33</mn><annotation-xml><cn>95.33</cn></annotation-xml><annotation>95.33</annotation></semantics></math></td><td><math><semantics><mn>57.27</mn><annotation-xml><cn>57.27</cn></annotation-xml><annotation>57.27</annotation></semantics></math></td><td><math><semantics><msub><mn>70.13</mn><mrow><mo></mo><mn>19.89</mn></mrow></msub><annotation-xml><apply><csymbol>subscript</csymbol><cn>70.13</cn><apply><csymbol>plus-or-minus</csymbol><cn>19.89</cn></apply></apply></annotation-xml><annotation>70.13_{\\pm 19.89}</annotation></semantics></math></td></tr><tr><th>+100 active labels</th><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><msub><mn>100.00</mn><mrow><mo></mo><mn>0.00</mn></mrow></msub><annotation-xml><apply><csymbol>subscript</csymbol><cn>100.00</cn><apply><csymbol>plus-or-minus</csymbol><cn>0.00</cn></apply></apply></annotation-xml><annotation>100.00_{\\pm 0.00}</annotation></semantics></math></td></tr><tr><th>Train on Tgt</th><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><msub><mn>100.00</mn><mrow><mo></mo><mn>0.00</mn></mrow></msub><annotation-xml><apply><csymbol>subscript</csymbol><cn>100.00</cn><apply><csymbol>plus-or-minus</csymbol><cn>0.00</cn></apply></apply></annotation-xml><annotation>100.00_{\\pm 0.00}</annotation></semantics></math></td></tr><tr><th><cite>Mudgal etal. (<a>2018</a>)</cite></th><td></td><td></td><td>100</td></tr></tbody></table>",
        "table_head": "<table><tbody><tr><th>Method</th><td>Prec</td><td>Recall</td><td>F1</td></tr><tr><th>Train on Src</th><td><math><semantics><mn>100.00</mn><annotation-xml><cn>100.00</cn></annotation-xml><annotation>100.00</annotation></semantics></math></td><td><math><semantics><mn>6.37</mn><annotation-xml><cn>6.37</cn></annotation-xml><annotation>6.37</annotation></semantics></math></td><td><math><semantics><msub><mn>11.76</mn><mrow><mo></mo><mn>6.84</mn></mrow></msub><annotation-xml><apply><csymbol>subscript</csymbol><cn>11.76</cn><apply><csymbol>plus-or-minus</csymbol><cn>6.84</cn></apply></apply></annotation-xml><annotation>11.76_{\\pm 6.84}</annotation></semantics></math></td></tr></tbody></table>",
        "citations": [
            "Other Genre Results. We present results from the restaurant and software genres.666We intend to apply our approaches to more genres, but unfortunately we lack large publicly available ER datasets in other genres than citation. Applications to non-English languages are also of interest. We leave this for future. Shown in Table 5 are results of transfer and active learning from Zomato-Yelp to Fodors-Zagats. Similarly to our extensive experiments in the citation genre, the dataset adaptation technique facilitates transfer learning significantly, and only 100 active learning labels are needed to achieve the same performance as the model trained with all target labels (894 labels). Fig.4 shows low-resource performance in the software genre. The relative performance among the 6 non-DL approaches differs to a great degree as the best non-DL model is now logistic regression, but deep active learning outperforms the rest with 1200 labeled examples (10.4% of training data). These results illustrate that our low-resource frameworks are effective in other genres as well."
        ],
        "caption": "Table 5: Transfer and active learning results in the restaurant genre. The target and source datasets are Fodors-Zagats and Zomato-Yelp respectively.",
        "footnotes": [""]
    },
    "2301.09521_5": {
        "html_table": "<table><thead><tr><th><table><tr><td>Development</td></tr><tr><td>Set Size</td></tr></table></th><th>Corner-Cases</th><th>Word-Occ</th><th>RoBERTa</th><th>R-SupCon</th></tr></thead><tbody><tr><th>Small</th><td rowspan=\"3\"><span>80%</span></td><td>63.30</td><td>36.63</td><td>82.30</td></tr><tr><th>Medium</th><td>71.50</td><td>52.03</td><td>88.63</td></tr><tr><th>Large</th><td>79.40</td><td>78.77</td><td>89.33</td></tr><tr><th>Small</th><td rowspan=\"3\"><span>50%</span></td><td>68.60</td><td>40.83</td><td>85.23</td></tr><tr><th>Medium</th><td>76.10</td><td>61.33</td><td>89.80</td></tr><tr><th>Large</th><td>81.10</td><td>82.00</td><td>91.73</td></tr><tr><th>Small</th><td rowspan=\"3\"><span>20%</span></td><td>66.60</td><td>39.83</td><td>87.87</td></tr><tr><th>Medium</th><td>76.20</td><td>61.13</td><td>92.60</td></tr><tr><th>Large</th><td>81.30</td><td>83.37</td><td>93.03</td></tr></tbody></table>",
        "table_head": "<table><thead><tr><th><table><tr><td>Development</td></tr><tr><td>Set Size</td></tr></table></th><th>Corner-Cases</th><th>Word-Occ</th><th>RoBERTa</th><th>R-SupCon</th></tr></thead><tbody><tr><th>Small</th><td rowspan=\"3\"><span>80%</span></td><td>63.30</td><td>36.63</td><td>82.30</td></tr></tbody></table>",
        "citations": [
                "Table 5 shows the results of the multi-class matching experiment. R-SupCon exhibits a significantly higher performance than the other two baselines for multi-class matching. Interestingly, the simple symbolic word occurrence baseline is able to significantly beat the fine-tuned RoBERTa model for small and medium-size datasets for multi-class matching, an effect that is not observable for the pair-wise variant. The comparison of the multi-class RoBERTa model to its pairwise counterpart shows that both methods achieve similar results given the large development size but the multi-class model is not able to achieve the same results for the smaller sizes, suggesting, that for a multi-class formulation, fine-tuning a transformer model requires a minimum amount of three to four offers per class to achieve good results. Finally, R-SupCon reaches 3-6% higher total F1s than its pair-wise counterpart even for smaller development set sizes, suggesting that this method is especially well suited for a multi-class matching scenario with the goal of recognizing a set of known products. The multi-class experiments underline the usefulness of the two versions for pair-wise and multi-class matching, as the performance of tested methods clearly differs between the versions."
            ],
            "caption": "Table 5. Results for multi-class matching over the dimensions development set size and amount of corner-cases. Results are micro-F1.",
            "footnotes": [""]
    }
}