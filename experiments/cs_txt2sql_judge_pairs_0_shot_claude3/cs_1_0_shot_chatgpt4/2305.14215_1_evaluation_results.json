{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[86.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "86.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[65.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[36.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[63.2 \u00b1 2.51]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[68.7 \u00b1 4.08]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[68.7 \u00b1 4.08]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[51.0 \u00b1 4.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[51.0 \u00b1 4.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[51.0 \u00b1 4.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Easy Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "73.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Medium Test-Suite Accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Hard Test-Suite Accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Extra Hard Test-Suite Accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[56.8 \u00b1 5.83]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[56.8 \u00b1 5.83]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[56.8 \u00b1 5.83]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[56.8 \u00b1 5.83]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[56.8 \u00b1 5.83]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Test-Suite Accuracy]",
                "outcomes": "[50.3 \u00b1 4.94]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Prompting Type": "Chain-of-Thought Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "In-Context Examples": "Randomly Selected",
                    "Shot Count": "8",
                    "API Doc Format": "Used",
                    "Repetition Count": "5",
                    "Standard Deviation": "Reported"
                },
                "measures": "[Overall Execution Accuracy]",
                "outcomes": "[53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 16,
    "total_ground_truth_claims": 80,
    "number_of_matches": 16
}