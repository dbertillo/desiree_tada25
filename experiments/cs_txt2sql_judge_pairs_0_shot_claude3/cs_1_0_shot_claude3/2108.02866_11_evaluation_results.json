{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "13.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "18.69"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "51.70"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.28"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "20.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "66.27"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "22.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "28.84"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "70.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.09"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "32.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "75.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.91"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "29.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "35.39"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.78"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "33.20"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "38.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.18"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "13.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "18.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.92"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "44.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "16.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "22.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.49"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.68, 47.12, 56.76, 67.73, 74.76, 80.25, 19.32, 34.54]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.38"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "13.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "18.69"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "51.70"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.28"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "20.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "66.27"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "22.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "28.84"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "70.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.09"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "32.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "75.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.91"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "29.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "35.39"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.78"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "33.20"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "38.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.18"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "13.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "18.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.92"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "44.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "16.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "22.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.49"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "textual",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[51.63, 71.00, 75.12, 78.42, 79.64, 80.25, 43.87, 59.95]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.38"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "13.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "18.69"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "51.70"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.28"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "20.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "66.27"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "22.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "28.84"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "70.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.09"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "32.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "75.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.91"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "29.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "35.39"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.78"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "33.20"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "38.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.18"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "13.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "18.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.92"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "44.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "16.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "22.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.49"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "BM25"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[9.31, 20.42, 26.18, 34.43, 40.66, 45.54, 9.98, 14.79]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.38"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "13.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "18.69"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "51.70"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.28"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "20.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "66.27"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "22.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "28.84"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "70.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.09"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "32.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "75.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.91"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "29.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "35.39"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.78"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "33.20"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "38.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.18"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "13.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "18.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.92"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "44.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "16.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "22.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.49"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "tabular",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[23.52, 34.82, 38.48, 42.24, 44.54, 45.54, 22.15, 28.81]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.38"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "13.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "18.69"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "51.70"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-1",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "50.28"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "20.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "66.27"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-5",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "68.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "22.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "28.84"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "70.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.09"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-10",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "74.10"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "25.24"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "32.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "75.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.91"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-25",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "29.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "35.39"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "80.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.78"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-50",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "33.20"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "38.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "84.14"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.18"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Index": "Top-100",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "Recall"
                ],
                "outcomes": [
                    "87.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "13.15"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "18.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.63"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "47.92"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MAP"
                ],
                "outcomes": [
                    "44.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "16.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked textual",
                    "Task": "Question Answering",
                    "Evidence Type": "Textual"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "22.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "AES tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.49"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked tabular",
                    "Task": "Question Answering",
                    "Evidence Type": "Tabular"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.34"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "dataset": "OpenNQ",
                    "index": "both",
                    "method": "Reranker"
                },
                "measures": "[Top-1, Top-5, Top-10, Top-25, Top-50, Top-100, MAP, MRR]",
                "outcomes": "[52.91, 72.33, 76.37, 80.03, 81.33, 82.22, 42.55, 61.31]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "OpenWikiSQL",
                    "Model": "Reranked hybrid",
                    "Task": "Question Answering",
                    "Evidence Type": "Hybrid"
                },
                "measures": [
                    "MRR"
                ],
                "outcomes": [
                    "58.38"
                ]
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 5,
    "total_ground_truth_claims": 40,
    "number_of_matches": 0
}