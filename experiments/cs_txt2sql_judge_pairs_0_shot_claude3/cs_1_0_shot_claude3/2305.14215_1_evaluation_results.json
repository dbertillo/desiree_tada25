{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[86.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "86.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[65.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[36.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.2 \u00b1 2.51, 68.7 \u00b1 4.08]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[51.0 \u00b1 4.29, 62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[51.0 \u00b1 4.29, 62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[51.0 \u00b1 4.29, 62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Standard",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[51.0 \u00b1 4.29, 62.5 \u00b1 4.01]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "73.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[44.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[23.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.8 \u00b1 5.83, 53.9 \u00b1 7.21]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Chain-of-Thought",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[50.3 \u00b1 4.94, 53.4 \u00b1 9.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.1"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[39.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[66.0 \u00b1 2.48, 68.9 \u00b1 3.44]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.0 \u00b1 2.51, 63.3 \u00b1 2.73]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[80.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[64.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "Least-to-Most",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[63.3 \u00b1 1.95, 73.8 \u00b1 1.72]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[53.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[67.4 \u00b1 1.89, 70.7 \u00b1 2.80]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[55.8 \u00b1 2.01, 65.8 \u00b1 2.29]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[89.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[74.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[52.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[38.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.4 \u00b1 2.05, 69.7 \u00b1 5.82]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Realistic",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "random"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[56.5 \u00b1 2.05, 63.3 \u00b1 4.19]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Easy",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[88.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Medium",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[71.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[56.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Extra Hard",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy]",
                "outcomes": "[45.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "QDecomp + InterCOL",
                    "dataset": "Spider Dev",
                    "difficulty": "Overall",
                    "in-context examples": "8-shot",
                    "example selection": "G3"
                },
                "measures": "[test-suite accuracy, standard execution accuracy]",
                "outcomes": "[68.8 \u00b1 1.16, 78.2 \u00b1 1.07]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "Codex",
                    "evaluation metric": "test-suite execution accuracy",
                    "reference": "Zhong et al., 2020"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "model": "RASAT+PICARD",
                    "reference": "Qi et al., 2022"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 42,
    "total_ground_truth_claims": 80,
    "number_of_matches": 33
}