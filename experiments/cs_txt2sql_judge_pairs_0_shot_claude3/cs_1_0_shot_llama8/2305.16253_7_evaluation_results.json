{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "75.1",
                    "RESDSQL": "77.9",
                    "NatSQL": "71.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "72.2",
                    "RESDSQL": "75.7",
                    "NatSQL": "72.5"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "73.7",
                    "RESDSQL": "77.8",
                    "NatSQL": "73.9"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Re-ranker": "N/A",
                    "SmBoP": "80.5",
                    "RESDSQL": "86.6",
                    "NatSQL": "81.1"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "0.3"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "BRIDGE v2": "21.8"
                },
                "measures": "[Table, 4]",
                "outcomes": [
                    "[Caption, Execution accuracy with re-ranking using the CodeBERT + GAT model. RR: Re-ranking all beams; ED+RR: Re-ranking beams after error detection.]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "bottom-up nature of its decoder"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "SmBoP": "less consistent on the test split"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "State-of-the-art text-to-SQL parsers": "autoregressive decoders"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "CodeBERT+GAT": "good generalization to unseen datasets"
                },
                "measures": "[Section, 3.2]",
                "outcomes": [
                    "[Section, 4.2.2]",
                    "[Dataset, KaggleDBQA Lee etal. (2021)]"
                ]
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 10,
    "total_ground_truth_claims": 28,
    "number_of_matches": 0
}