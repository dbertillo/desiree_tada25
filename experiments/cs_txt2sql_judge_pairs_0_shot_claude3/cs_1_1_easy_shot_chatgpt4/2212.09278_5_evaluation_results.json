{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "method": "EditSQL",
                    "SQL difficulty": "Easy",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Easy]",
                "outcomes": "[68.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "EditSQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "EditSQL",
                    "SQL difficulty": "Medium",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Medium]",
                "outcomes": "[40.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "EditSQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "40.6"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "EditSQL",
                    "SQL difficulty": "Hard",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Hard]",
                "outcomes": "[26.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "EditSQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "26.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "EditSQL",
                    "SQL difficulty": "Extra",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Extra]",
                "outcomes": "[12.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "EditSQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Extra"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "12.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "IG-SQL",
                    "SQL difficulty": "Easy",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Easy]",
                "outcomes": "[70.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "IG-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "70.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "IG-SQL",
                    "SQL difficulty": "Medium",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Medium]",
                "outcomes": "[45.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "IG-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "45.4"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "IG-SQL",
                    "SQL difficulty": "Hard",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Hard]",
                "outcomes": "[29.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "IG-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "29.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "IG-SQL",
                    "SQL difficulty": "Extra",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Extra]",
                "outcomes": "[18.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "IG-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Extra"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "18.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "R2SQL",
                    "SQL difficulty": "Easy",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Easy]",
                "outcomes": "[75.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "R2SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "75.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "R2SQL",
                    "SQL difficulty": "Medium",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Medium]",
                "outcomes": "[51.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "R2SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "51.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "R2SQL",
                    "SQL difficulty": "Hard",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Hard]",
                "outcomes": "[35.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "R2SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "35.2"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "R2SQL",
                    "SQL difficulty": "Extra",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Extra]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "R2SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Extra"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "21.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "CQR-SQL",
                    "SQL difficulty": "Easy",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Easy]",
                "outcomes": "[80.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "CQR-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "80.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "CQR-SQL",
                    "SQL difficulty": "Medium",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Medium]",
                "outcomes": "[68.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "CQR-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "68.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "CQR-SQL",
                    "SQL difficulty": "Hard",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Hard]",
                "outcomes": "[46.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "CQR-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "46.2"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "CQR-SQL",
                    "SQL difficulty": "Extra",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Extra]",
                "outcomes": "[43.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "CQR-SQL",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Extra"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "43.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "MIGA+PICARD",
                    "SQL difficulty": "Easy",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Easy]",
                "outcomes": "[81.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "MIGA+PICARD",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "81.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "MIGA+PICARD",
                    "SQL difficulty": "Medium",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Medium]",
                "outcomes": "[66.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "MIGA+PICARD",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "66.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "MIGA+PICARD",
                    "SQL difficulty": "Hard",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Hard]",
                "outcomes": "[44.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "MIGA+PICARD",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "44.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "method": "MIGA+PICARD",
                    "SQL difficulty": "Extra",
                    "dataset": "SparC dev set",
                    "task": "FUP",
                    "metric type": "QM accuracy"
                },
                "measures": "[Extra]",
                "outcomes": "[41.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "MIGA+PICARD",
                    "Dataset": "SparC dev set",
                    "Task": "SQL prediction",
                    "Difficulty": "Extra"
                },
                "measures": [
                    "QM accuracy"
                ],
                "outcomes": [
                    "41.8"
                ]
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 20,
    "total_ground_truth_claims": 20,
    "number_of_matches": 20
}