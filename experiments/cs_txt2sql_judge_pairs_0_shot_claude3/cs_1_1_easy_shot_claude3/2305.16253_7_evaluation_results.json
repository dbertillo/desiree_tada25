{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "SmBoP",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[80.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[75.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[77.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "RESDSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[86.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "N/A",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[71.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "RR",
                    "Re-ranking method": "Re-ranking all beams",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[72.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Re-ranker": "ED + RR",
                    "Re-ranking method": "Re-ranking beams after error detection",
                    "Metric": "Execution accuracy"
                },
                "measures": "[Execution accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "NatSQL",
                    "Metric": "Beam Hit"
                },
                "measures": "[Beam Hit]",
                "outcomes": "[81.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[20.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "42.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "39.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "40.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "44.82"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.55"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.85"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.93"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.52"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.37"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "10.02"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v1",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "54.40"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.96"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "55.79"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "52.03"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "11.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.13"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.43"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "UNISAR",
                    "Pre-trained Language Model": "BART",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "12.65"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.74"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.68"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.97"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "PICARD",
                    "Pre-trained Language Model": "T5",
                    "Dataset": "BiaSpider v2",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "9.58"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "RoBERTa-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "53.56"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Neg",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "51.25"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Random-Pos",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "50.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "BRIDGE v2",
                    "Re-ranker": "CodeBERT+GAT",
                    "Dataset": "KaggleDBQA",
                    "Metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[21.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "RATSQL",
                    "Pre-trained Language Model": "BERT",
                    "Dataset": "BiaSpider v3",
                    "Bias Type": "Comparative",
                    "Evaluation Type": "Text-to-SQL",
                    "Number of Models Evaluated": "3"
                },
                "measures": [
                    "Bias Score"
                ],
                "outcomes": [
                    "49.71"
                ]
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 14,
    "total_ground_truth_claims": 28,
    "number_of_matches": 0
}