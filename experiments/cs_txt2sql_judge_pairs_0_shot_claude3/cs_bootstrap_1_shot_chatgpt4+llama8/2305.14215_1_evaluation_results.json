{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[86.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "86.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[73.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "73.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[88.1]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.1"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[68.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "68.9"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[89.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.8"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[70.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.7"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[68.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Dev",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[78.2]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[51.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "51.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Standard Prompting",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[62.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "62.5"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[50.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Chain-of-Thought",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[53.4]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "53.4"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "55.0"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "Least-to-Most",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "63.3"
                ]
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[55.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "QDecomp",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[65.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[56.5]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "Random",
                    "API Doc Format": "Included"
                },
                "measures": "[Standard Execution Accuracy]",
                "outcomes": "[63.3]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "65.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "50.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "36.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "63.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.08"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.29"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Standard",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "4.01"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "44.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "23.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "5.83"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.21"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "4.94"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain-of-Thought",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "9.19"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "39.5"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "66.0"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.48"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.44"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.51"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.73"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "80.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "64.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "52.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.95"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "73.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Least-to-Most (G3)",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.72"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "71.3"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "53.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "38.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "67.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.89"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "7.53"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.12"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "69.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "3.61"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "88.9"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "56.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "45.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "68.8"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.16"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.07"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "58.6"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "2.04"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "70.2"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.54"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Easy"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "89.7"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Medium"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "74.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "57.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Extra Hard"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "46.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "69.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.41"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "72.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Dev",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "1.22"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Test-suite accuracy"
                ],
                "outcomes": [
                    "59.1"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Test-suite accuracy"
                ],
                "outcomes": [
                    "1.66"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Execution accuracy"
                ],
                "outcomes": [
                    "71.4"
                ]
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "+ InterCOL (G3)",
                    "Dataset": "Spider Realistic",
                    "Difficulty": "Easy",
                    "Prompting Type": "+ InterCOL",
                    "Evaluation Metric": "Standard Execution Accuracy",
                    "Experiment Type": "8-shot",
                    "In-Context Example Selection": "G3",
                    "API Doc Format": "Included"
                },
                "measures": "[Test-Suite Accuracy]",
                "outcomes": "[-]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "QDecomp + InterCoL + InterCoT",
                    "Dataset": "Spider Realistic",
                    "Model": "Codex",
                    "Number of shots": "8",
                    "Difficulty": "Overall"
                },
                "measures": [
                    "Standard deviation of Execution accuracy"
                ],
                "outcomes": [
                    "2.06"
                ]
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 23,
    "total_ground_truth_claims": 80,
    "number_of_matches": 15
}