{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "MLN_version": "MLN(Fig1)",
                    "heuristics": "none"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.513, 0.532, 0.602, 0.544]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.513]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "MLN_version": "MLN(S&D)",
                    "heuristics": "complex heuristics by Singla and Domingos",
                    "additional_procedure": "TFIDF-based matching with canopies"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.520, 0.573, 0.627, 0.629]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.532]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "MLN_version": "MLN(S&D)",
                    "heuristics": "complex heuristics by Singla and Domingos",
                    "additional_procedure": "TFIDF-based matching with canopies"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.520, 0.573, 0.627, 0.629]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "MLN_version": "MLN(S&D)",
                    "heuristics": "complex heuristics by Singla and Domingos",
                    "additional_procedure": "TFIDF-based matching with canopies"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.520, 0.573, 0.627, 0.629]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "MLN_version": "MLN(S&D)",
                    "heuristics": "complex heuristics by Singla and Domingos",
                    "additional_procedure": "TFIDF-based matching with canopies"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.520, 0.573, 0.627, 0.629]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.520]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.532]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.573]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR",
                    "parameter_w": "1"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.680, 0.836, 0.860, 0.908]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.680]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.532]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.573]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.836]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "model": "ProPPR"
                },
                "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                "outcomes": "[0.800, 0.840, 0.869, 0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.800]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.532]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.573]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.836]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.840]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.869]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "table": "Table 6",
                    "task": "citation-matching",
                    "dataset": "CORA",
                    "evaluation_procedure": "same for all models",
                    "training_system": "Alchemy",
                    "training_commands": "recommended commands for CORA",
                    "comparison": "ProPPR vs MLN(S&D)",
                    "result": "title performance not reported by Singla and Domingos"
                }
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.900]"
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 5,
    "total_ground_truth_claims": 16,
    "number_of_matches": 4
}