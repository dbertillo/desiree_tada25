{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "sub-task": "Sub-task 1",
                    "metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "sub-task": "Sub-task 2",
                    "metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "sub-task": "Sub-task 3",
                    "metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "sub-task": "Sub-task 3",
                    "metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "sub-task": "Sub-task 3",
                    "metric": "Rouge-L"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "baseline",
                    "metric": "Appropriateness"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "sub-task": "Sub-task 1",
                    "metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "sub-task": "Sub-task 2",
                    "metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "sub-task": "Sub-task 3",
                    "metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "sub-task": "Sub-task 3",
                    "metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "sub-task": "Sub-task 3",
                    "metric": "Rouge-L"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "metric": "Accuracy"
                },
                "measures": "[Accuracy]",
                "outcomes": "[4.2722]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[4.2722]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "system": "our system",
                    "team": "Team 11",
                    "metric": "Appropriateness"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[4.2619]"
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 18,
    "total_ground_truth_claims": 14,
    "number_of_matches": 14
}