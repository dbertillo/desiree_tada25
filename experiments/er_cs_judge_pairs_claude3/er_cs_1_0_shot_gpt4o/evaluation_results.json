{
    "2104.09677_5": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 5",
                        "data sets": "German census data sets",
                        "attribute selection threshold": "0.6",
                        "score weight": "0.5",
                        "st": "0.8",
                        "step": "Attribute selection step (Algorithm 1)"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[7,903]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "German census data sets",
                        "Similarity threshold": "0.8",
                        "Score weight": "0.5",
                        "Attribute selection threshold": "0.6",
                        "Step": "Attribute selection",
                        "Algorithm": "Algorithm1"
                    },
                    "measures": "[Runtime]",
                    "outcomes": "[7903]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 5",
                        "data sets": "German census data sets",
                        "attribute selection threshold": "0.6",
                        "score weight": "0.5",
                        "st": "0.8",
                        "step": "Signature generation step (Algorithm 2)"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[4,573]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "German census data sets",
                        "Similarity threshold": "0.8",
                        "Score weight": "0.5",
                        "Attribute selection threshold": "0.6",
                        "Step": "Signature generation",
                        "Algorithm": "Algorithm2"
                    },
                    "measures": "[Runtime]",
                    "outcomes": "[4573]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 5",
                        "data sets": "German census data sets",
                        "attribute selection threshold": "0.6",
                        "score weight": "0.5",
                        "st": "0.8",
                        "step": "Record matching step (Algorithm 3)"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[3,438]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "German census data sets",
                        "Similarity threshold": "0.8",
                        "Score weight": "0.5",
                        "Attribute selection threshold": "0.6",
                        "Step": "Record matching",
                        "Algorithm": "Algorithm3"
                    },
                    "measures": "[Runtime]",
                    "outcomes": "[3438]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 5",
                        "data sets": "German census data sets",
                        "attribute selection threshold": "0.6",
                        "score weight": "0.5",
                        "st": "0.8"
                    },
                    "measures": "[precision]",
                    "outcomes": "[0.999]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "German census data sets",
                        "Similarity threshold": "0.8",
                        "Score weight": "0.5",
                        "Attribute selection threshold": "0.6"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[0.999]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 5",
                        "data sets": "German census data sets",
                        "attribute selection threshold": "0.6",
                        "score weight": "0.5",
                        "st": "0.8"
                    },
                    "measures": "[recall]",
                    "outcomes": "[0.962]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "German census data sets",
                        "Similarity threshold": "0.8",
                        "Score weight": "0.5",
                        "Attribute selection threshold": "0.6"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[0.962]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 5,
        "total_ground_truth_claims": 5,
        "number_of_matches": 5
    },
    "2211.02161_4": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "DBLP-ACM-C"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[6]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "DBLP-ACM-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[6]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "DBLP-ACM-D"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[6]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "DBLP-ACM-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[6]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "DBLP-Scholar-C"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[70]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "DBLP-Scholar-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[70]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "DBLP-Scholar-D"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[71]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "DBLP-Scholar-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[71]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "iTune-Amazon"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[91]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "iTune-Amazon",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[91]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "Music-Brainz"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[16]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "Music-Brainz",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[16]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "Amazon-Google"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[11]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "Amazon-Google",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[11]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "NCVR"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[462]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "NCVR",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[462]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BF",
                        "citation": "[45, 46, 10]",
                        "dataset": "European Census"
                    },
                    "measures": "[45, 46, 10]",
                    "outcomes": [
                        "[runtime]",
                        "[58]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BF",
                        "Dataset": "European Census",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[58]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "DBLP-ACM-C"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[8]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "DBLP-ACM-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[8]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "DBLP-ACM-D"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[9]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "DBLP-ACM-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "DBLP-Scholar-C"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[75]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "DBLP-Scholar-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[75]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "DBLP-Scholar-D"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[75]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "DBLP-Scholar-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[75]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "iTune-Amazon"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[94]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "iTune-Amazon",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[94]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "Music-Brainz"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[18]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "Music-Brainz",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[18]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "Amazon-Google"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[13]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "Amazon-Google",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[13]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "NCVR"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[473]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "NCVR",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[473]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-BF",
                        "citation": "[18, 19, 7]",
                        "dataset": "European Census"
                    },
                    "measures": "[18, 19, 7]",
                    "outcomes": [
                        "[runtime]",
                        "[73]"
                    ]
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-BF",
                        "Dataset": "European Census",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[73]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "DBLP-ACM-C"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "DBLP-ACM-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[8]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "DBLP-ACM-D"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "DBLP-ACM-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "DBLP-Scholar-C"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[77]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "DBLP-Scholar-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[77]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "DBLP-Scholar-D"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[78]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "DBLP-Scholar-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[78]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "iTune-Amazon"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[96]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "iTune-Amazon",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[96]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "Music-Brainz"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[18]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "Music-Brainz",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[18]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "Amazon-Google"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[14]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "Amazon-Google",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[14]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "NCVR"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[475]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "NCVR",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[475]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DL-BF",
                        "dataset": "European Census"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[75]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DL-BF",
                        "Dataset": "European Census",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[75]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "DBLP-ACM-C"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[10]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "DBLP-ACM-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[10]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "DBLP-ACM-D"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[12]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "DBLP-ACM-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[12]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "DBLP-Scholar-C"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[92]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "DBLP-Scholar-C",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[92]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "DBLP-Scholar-D"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[91]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "DBLP-Scholar-D",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[91]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "iTune-Amazon"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[103]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "iTune-Amazon",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[103]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "Music-Brainz"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[25]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "Music-Brainz",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[25]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "Amazon-Google"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[19]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "Amazon-Google",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[19]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "NCVR"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[491]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "NCVR",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[491]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "DP-DL-BF",
                        "dataset": "European Census"
                    },
                    "measures": "[runtime]",
                    "outcomes": "[82]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "DP-DL-BF",
                        "Dataset": "European Census",
                        "Unit": "seconds"
                    },
                    "measures": "[Average runtime]",
                    "outcomes": "[82]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 36,
        "total_ground_truth_claims": 36,
        "number_of_matches": 36
    },
    "2004.02008_4": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "DP",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.03]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "DP",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.03]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "DP",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "DP",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "DP",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "DP",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "DP",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "DP",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "PY",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "PY",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "PY",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "PY",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "PY",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "PY",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "PY",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "PY",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "ESCNB",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCNB",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "ESCNB",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCNB",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.04]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "ESCNB",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.01]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCNB",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.01]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "ESCNB",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCNB",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "ESCD",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCD",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SDS",
                        "model": "ESCD",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.02]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCD",
                        "Dataset": "SDS",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.02]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "ESCD",
                        "metric": "FNR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.01]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCD",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FNR SE]",
                    "outcomes": "[0.01]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "SIPP",
                        "model": "ESCD",
                        "metric": "FDR SE",
                        "method": "MCMC",
                        "precision": "one decimal place",
                        "burn-in": "5000 iterations",
                        "software": "R package CODA",
                        "source": "Table 4"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ESCD",
                        "Dataset": "SIPP",
                        "Metric Type": "Time-series MCMC error",
                        "Reported Precision": "One decimal place",
                        "Computation Method": "summary.mcmc from R package CODA"
                    },
                    "measures": "[FDR SE]",
                    "outcomes": "[0.01]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 16,
        "total_ground_truth_claims": 16,
        "number_of_matches": 16
    },
    "2310.12450_3": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Baseline",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[87.64]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Baseline",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[87.64]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Baseline",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[77.27]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Baseline",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[77.27]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Baseline",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[75.89]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Baseline",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[75.89]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Baseline",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[71.46]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Baseline",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[71.46]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BLINK*",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3",
                        "implementation": "our implementation"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[94.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BLINK*",
                        "Implementation": "Custom",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[94.30]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BLINK*",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3",
                        "implementation": "our implementation"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[75.40]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BLINK*",
                        "Implementation": "Custom",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[75.40]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BLINK*",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3",
                        "implementation": "our implementation"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[79.95]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BLINK*",
                        "Implementation": "Custom",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[79.95]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "BLINK*",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3",
                        "implementation": "our implementation"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[73.50]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "BLINK*",
                        "Implementation": "Custom",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[73.50]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Uni-MPR",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[91.43]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Uni-MPR",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[91.43]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Uni-MPR",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[79.07]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Uni-MPR",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[79.07]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Uni-MPR",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[75.60]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Uni-MPR",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[75.60]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Uni-MPR",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[73.53]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Uni-MPR",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[73.53]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bi-MPR",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[92.84]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bi-MPR",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[92.84]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bi-MPR",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[81.93]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bi-MPR",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[81.93]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bi-MPR",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[77.37]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bi-MPR",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[77.37]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bi-MPR",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[73.88]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bi-MPR",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[73.88]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[94.42]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[94.42]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[81.29]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[81.29]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[77.80]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[77.80]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[76.51]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[76.51]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS (w/o selecting)",
                        "subset": "High Overlap (HO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[92.72]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS (w/o selecting)",
                        "Subset": "High Overlap (HO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[92.72]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS (w/o selecting)",
                        "subset": "Multiple Categories (MC)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[78.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS (w/o selecting)",
                        "Subset": "Multiple Categories (MC)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[78.30]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS (w/o selecting)",
                        "subset": "Ambiguous Substring (AS)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[79.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS (w/o selecting)",
                        "Subset": "Ambiguous Substring (AS)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[79.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "ReS (w/o selecting)",
                        "subset": "Low Overlap (LO)",
                        "source": "Table 3"
                    },
                    "measures": "[accuracy]",
                    "outcomes": "[75.50]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "ReS (w/o selecting)",
                        "Subset": "Low Overlap (LO)"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[75.50]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 31,
        "total_ground_truth_claims": 24,
        "number_of_matches": 24
    },
    "2404.05566_3": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "training",
                        "rank": "1",
                        "description": "highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[76.74]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "1",
                        "Dataset": "Training"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[76.74]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "test",
                        "rank": "1",
                        "description": "highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[79.55]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "1",
                        "Dataset": "Test"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[79.55]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "training",
                        "rank": "2",
                        "description": "second-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[4.92]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "2",
                        "Dataset": "Training"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[4.92]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "test",
                        "rank": "2",
                        "description": "second-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[4.19]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "2",
                        "Dataset": "Test"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[4.19]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "training",
                        "rank": "3",
                        "description": "third-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[1.76]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "3",
                        "Dataset": "Training"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[1.76]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "test",
                        "rank": "3",
                        "description": "third-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[1.14]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "3",
                        "Dataset": "Test"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[1.14]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "training",
                        "rank": "4",
                        "description": "fourth-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[1.09]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "4",
                        "Dataset": "Training"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[1.09]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "test",
                        "rank": "4",
                        "description": "fourth-highest probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[0.64]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": "4",
                        "Dataset": "Test"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[0.64]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "training",
                        "rank": "\u2265 5",
                        "description": "fifth or lower probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[15.49]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": ">= 5",
                        "Dataset": "Training"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[15.49]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "year1": "2014",
                        "year2": "2016",
                        "dataset": "test",
                        "rank": "\u2265 5",
                        "description": "fifth or lower probability corresponds to the true match"
                    },
                    "measures": "[percentage]",
                    "outcomes": "[14.48]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Rank": ">= 5",
                        "Dataset": "Test"
                    },
                    "measures": "[Percentage of correctly matching households]",
                    "outcomes": "[14.48]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 12,
        "total_ground_truth_claims": 10,
        "number_of_matches": 10
    },
    "1308.3357_1": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "disk space estimation",
                        "dataset": "SP2bench",
                        "serialization": "N-Triples",
                        "database": "CouchDB",
                        "compression": "off"
                    },
                    "measures": "[size (kB/1K triples)]",
                    "outcomes": "[157]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Serialization": "N-Triples",
                        "Dataset": "SP2bench",
                        "Experiment": "Disk space estimation",
                        "Database": "CouchDB",
                        "Database file compression": "Off"
                    },
                    "measures": "[Size (kB/1K triples)]",
                    "outcomes": "[157]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "disk space estimation",
                        "dataset": "SP2bench",
                        "serialization": "Model 1",
                        "database": "CouchDB",
                        "compression": "off"
                    },
                    "measures": "[size (kB/1K triples)]",
                    "outcomes": "[143]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Serialization": "Model 1",
                        "Dataset": "SP2bench",
                        "Experiment": "Disk space estimation",
                        "Database": "CouchDB",
                        "Database file compression": "Off"
                    },
                    "measures": "[Size (kB/1K triples)]",
                    "outcomes": "[143]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "disk space estimation",
                        "dataset": "SP2bench",
                        "serialization": "Model 2",
                        "database": "CouchDB",
                        "compression": "off"
                    },
                    "measures": "[size (kB/1K triples)]",
                    "outcomes": "[157]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Serialization": "Model 2",
                        "Dataset": "SP2bench",
                        "Experiment": "Disk space estimation",
                        "Database": "CouchDB",
                        "Database file compression": "Off"
                    },
                    "measures": "[Size (kB/1K triples)]",
                    "outcomes": "[157]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "disk space estimation",
                        "dataset": "SP2bench",
                        "serialization": "Document per quad",
                        "database": "CouchDB",
                        "compression": "off"
                    },
                    "measures": "[size (kB/1K triples)]",
                    "outcomes": "[418]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Serialization": "Document per quad",
                        "Dataset": "SP2bench",
                        "Experiment": "Disk space estimation",
                        "Database": "CouchDB",
                        "Database file compression": "Off"
                    },
                    "measures": "[Size (kB/1K triples)]",
                    "outcomes": "[418]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 4,
        "total_ground_truth_claims": 4,
        "number_of_matches": 4
    },
    "2111.01767_2": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "real data experiment",
                        "dataset": "Beijing Air Quality Data",
                        "method": "naive",
                        "metric": "average REE",
                        "replications": "100",
                        "comparison": "local shuffling prior",
                        "context": "without regularization"
                    },
                    "measures": "[Corr est - Corr * Frobenius norm]",
                    "outcomes": "[0.76]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "naive",
                        "Experiment": "real data experiment",
                        "Dataset": "Beijing Air Quality Data",
                        "Replication count": "100",
                        "Prior": "local shuffling permutation"
                    },
                    "measures": "[REE, Standard Error]",
                    "outcomes": "[0.76, 0.0012]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "real data experiment",
                        "dataset": "Beijing Air Quality Data",
                        "method": "EM",
                        "metric": "average REE",
                        "replications": "100",
                        "comparison": "local shuffling prior",
                        "context": "without regularization"
                    },
                    "measures": "[Corr est - Corr * Frobenius norm]",
                    "outcomes": "[1.97]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "EM",
                        "Experiment": "real data experiment",
                        "Dataset": "Beijing Air Quality Data",
                        "Replication count": "100",
                        "Prior": "local shuffling permutation"
                    },
                    "measures": "[REE, Standard Error]",
                    "outcomes": "[1.97, 0.0111]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "real data experiment",
                        "dataset": "Beijing Air Quality Data",
                        "method": "EML",
                        "metric": "average REE",
                        "replications": "100",
                        "comparison": "local shuffling prior",
                        "context": "with regularization"
                    },
                    "measures": "[Corr est - Corr * Frobenius norm]",
                    "outcomes": "[0.34]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "EML",
                        "Experiment": "real data experiment",
                        "Dataset": "Beijing Air Quality Data",
                        "Replication count": "100",
                        "Prior": "local shuffling permutation"
                    },
                    "measures": "[REE, Standard Error]",
                    "outcomes": "[0.34, 0.0010]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 6,
        "total_ground_truth_claims": 3,
        "number_of_matches": 3
    },
    "1906.08042_5": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Src",
                        "precision": "100.00",
                        "recall": "6.37",
                        "f1_score": "11.76 \u00b1 6.84"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 6.37, 11.76 \u00b1 6.84]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[100.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+Adaptation",
                        "precision": "95.33",
                        "recall": "57.27",
                        "f1_score": "70.13 \u00b1 19.89"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[95.33, 57.27, 70.13 \u00b1 19.89]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[6.37]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+Adaptation",
                        "precision": "95.33",
                        "recall": "57.27",
                        "f1_score": "70.13 \u00b1 19.89"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[95.33, 57.27, 70.13 \u00b1 19.89]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[11.76, 6.84]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+Adaptation",
                        "precision": "95.33",
                        "recall": "57.27",
                        "f1_score": "70.13 \u00b1 19.89"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[95.33, 57.27, 70.13 \u00b1 19.89]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[95.33]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+100 active labels",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[6.37]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+100 active labels",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[11.76, 6.84]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+100 active labels",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[57.27]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+100 active labels",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[70.13, 19.89]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "+100 active labels",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+100 active labels",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[100.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[6.37]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[11.76, 6.84]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[57.27]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[70.13, 19.89]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+100 active labels",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[100.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+100 active labels",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[100.00, 0.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Train on Tgt",
                        "precision": "100.00",
                        "recall": "100.00",
                        "f1_score": "100.00 \u00b1 0.00"
                    },
                    "measures": "[precision, recall, f1_score]",
                    "outcomes": "[100.00, 100.00, 100.00 \u00b1 0.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Tgt",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[100.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[6.37]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Src",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[11.76, 6.84]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[57.27]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+Adaptation",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[70.13, 19.89]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+100 active labels",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[100.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "+100 active labels",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[100.00, 0.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Tgt",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[100.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Train on Tgt",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1, F1 Standard Deviation]",
                    "outcomes": "[100.00, 0.00]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "genre": "restaurant",
                        "source_dataset": "Zomato-Yelp",
                        "target_dataset": "Fodors-Zagats",
                        "method": "Mudgal et al. (2018)",
                        "f1_score": "100"
                    },
                    "measures": "[f1_score]",
                    "outcomes": "[100]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Mudgal etal. (2018)",
                        "Genre": "restaurant",
                        "Target Dataset": "Fodors-Zagats",
                        "Source Dataset": "Zomato-Yelp"
                    },
                    "measures": "[F1]",
                    "outcomes": "[100]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 5,
        "total_ground_truth_claims": 13,
        "number_of_matches": 5
    },
    "2106.14444_1": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "sub-task": "Sub-task 1",
                        "metric": "F1"
                    },
                    "measures": "[F1]",
                    "outcomes": "[0.9455]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Sub-task": "Sub-task 1",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[F1]",
                    "outcomes": "[0.9455]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "sub-task": "Sub-task 2",
                        "metric": "R@1"
                    },
                    "measures": "[R@1]",
                    "outcomes": "[0.6201]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Sub-task": "Sub-task 2",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[R@1]",
                    "outcomes": "[0.6201]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "sub-task": "Sub-task 3",
                        "metric": "BLEU-1"
                    },
                    "measures": "[BLEU-1]",
                    "outcomes": "[0.3031]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[BLEU-1]",
                    "outcomes": "[0.3031]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "sub-task": "Sub-task 3",
                        "metric": "METEOR"
                    },
                    "measures": "[METEOR]",
                    "outcomes": "[0.2983]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[METEOR]",
                    "outcomes": "[0.2983]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "sub-task": "Sub-task 3",
                        "metric": "Rouge-L"
                    },
                    "measures": "[Rouge-L]",
                    "outcomes": "[0.3039]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[Rouge-L]",
                    "outcomes": "[0.3039]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "metric": "Accuracy"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[3.7155]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Dataset": "DSTC9",
                        "Evaluation": "Human evaluation on a scale of 1-5"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[3.7155]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "baseline",
                        "metric": "Appropriateness"
                    },
                    "measures": "[Appropriateness]",
                    "outcomes": "[3.9386]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Baseline",
                        "Dataset": "DSTC9",
                        "Evaluation": "Human evaluation on a scale of 1-5"
                    },
                    "measures": "[Appropriateness]",
                    "outcomes": "[3.9386]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "sub-task": "Sub-task 1",
                        "metric": "F1"
                    },
                    "measures": "[F1]",
                    "outcomes": "[0.9675]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Sub-task": "Sub-task 1",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[F1]",
                    "outcomes": "[0.9675]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "sub-task": "Sub-task 2",
                        "metric": "R@1"
                    },
                    "measures": "[R@1]",
                    "outcomes": "[0.8702]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Sub-task": "Sub-task 2",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[R@1]",
                    "outcomes": "[0.8702]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "sub-task": "Sub-task 3",
                        "metric": "BLEU-1"
                    },
                    "measures": "[BLEU-1]",
                    "outcomes": "[0.3743]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[BLEU-1]",
                    "outcomes": "[0.3743]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "sub-task": "Sub-task 3",
                        "metric": "METEOR"
                    },
                    "measures": "[METEOR]",
                    "outcomes": "[0.3854]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[METEOR]",
                    "outcomes": "[0.3854]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "sub-task": "Sub-task 3",
                        "metric": "Rouge-L"
                    },
                    "measures": "[Rouge-L]",
                    "outcomes": "[0.3797]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Sub-task": "Sub-task 3",
                        "Dataset": "DSTC9"
                    },
                    "measures": "[Rouge-L]",
                    "outcomes": "[0.3797]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "metric": "Accuracy"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[4.2722]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Dataset": "DSTC9",
                        "Evaluation": "Human evaluation on a scale of 1-5"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[4.2722]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "system": "our system",
                        "team": "Team 11",
                        "metric": "Appropriateness"
                    },
                    "measures": "[Appropriateness]",
                    "outcomes": "[4.2619]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "System": "Our system",
                        "Dataset": "DSTC9",
                        "Evaluation": "Human evaluation on a scale of 1-5"
                    },
                    "measures": "[Appropriateness]",
                    "outcomes": "[4.2619]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 18,
        "total_ground_truth_claims": 14,
        "number_of_matches": 14
    },
    "2209.07569_6": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".829",
                        "Recall": ".991",
                        "F1": ".901",
                        "Accuracy": ".960",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.829, .991, .901, .960]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".829",
                        "Recall": ".991",
                        "F1": ".901",
                        "Accuracy": ".960",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.829, .991, .901, .960]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".829",
                        "Recall": ".991",
                        "F1": ".901",
                        "Accuracy": ".960",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.829, .991, .901, .960]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.901]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".921",
                        "Recall": ".905",
                        "F1": ".912",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.921, .905, .912, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".921",
                        "Recall": ".905",
                        "F1": ".912",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.921, .905, .912, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".921",
                        "Recall": ".905",
                        "F1": ".912",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.921, .905, .912, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".921",
                        "Recall": ".905",
                        "F1": ".912",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.921, .905, .912, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".921",
                        "Recall": ".905",
                        "F1": ".912",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.921, .905, .912, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.905]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".933",
                        "Recall": ".985",
                        "F1": ".958",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "57.6 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.933, .985, .958, .985, 57.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.933]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".852",
                        "Recall": ".812",
                        "F1": ".831",
                        "Accuracy": ".969",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.852, .812, .831, .969]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.852]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.812]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.831]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".854",
                        "Recall": ".772",
                        "F1": ".810",
                        "Accuracy": ".966",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.854, .772, .810, .966]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.854]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.812]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.831]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.772]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.810]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.966]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".903",
                        "Recall": ".792",
                        "F1": ".844",
                        "Accuracy": ".985",
                        "EFsubscriptE_{F}": "7.7 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.903, .792, .844, .985, 7.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.903]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.812]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.831]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.772]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.810]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.966]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.792]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.844]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[7.7 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence",
                        "Precision": ".786",
                        "Recall": ".745",
                        "F1": ".761",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.786, .745, .761, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.786]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.812]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.831]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.772]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.810]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.966]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.792]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.844]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[7.7 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.745]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.761]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence",
                        "Precision": ".808",
                        "Recall": ".713",
                        "F1": ".757",
                        "Accuracy": ".948",
                        "EFsubscriptE_{F}": "-"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy]",
                    "outcomes": "[.808, .713, .757, .948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.808]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.829]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.991]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.960]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.921]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.958]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AmazonMI",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[57.6 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.812]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.831]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.969]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.772]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.810]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.966]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.792]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.844]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Walmart-Amazon",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[E_subscript{F}]",
                    "outcomes": "[7.7 %]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.745]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.761]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "In-parallel",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[.713]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[F1]",
                    "outcomes": "[.757]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "Multi-label",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Accuracy]",
                    "outcomes": "[.948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence",
                        "Precision": ".775",
                        "Recall": ".788",
                        "F1": ".782",
                        "Accuracy": ".950",
                        "EFsubscriptE_{F}": "8.8 %"
                    },
                    "measures": "[Precision, Recall, F1, Accuracy, EFsubscriptE_{F}]",
                    "outcomes": "[.775, .788, .782, .950, 8.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WDC",
                        "Model": "FlexER",
                        "Intent": "Equivalence"
                    },
                    "measures": "[Precision]",
                    "outcomes": "[.775]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 9,
        "total_ground_truth_claims": 39,
        "number_of_matches": 9
    },
    "2301.09521_5": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "80%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[63.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "80%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[63.30]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "80%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[36.63]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "80%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[36.63]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "80%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[82.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "80%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[82.30]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "80%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[71.50]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "80%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[71.50]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "80%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[52.03]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "80%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[52.03]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "80%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[88.63]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "80%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[88.63]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "80%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[79.40]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "80%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[79.40]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "80%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[78.77]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "80%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[78.77]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "80%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[89.33]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "80%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[89.33]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "50%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[68.60]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "50%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[68.60]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "50%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[40.83]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "50%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[40.83]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "50%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[85.23]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "50%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[85.23]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "50%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[76.10]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "50%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[76.10]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "50%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[61.33]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "50%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[61.33]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "50%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[89.80]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "50%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[89.80]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "50%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[81.10]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "50%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[81.10]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "50%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[82.00]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "50%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[82.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "50%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[91.73]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "50%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[91.73]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "20%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[66.60]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "20%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[66.60]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "20%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[39.83]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "20%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[39.83]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Small",
                        "corner-cases": "20%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[87.87]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Small",
                        "Corner-Cases": "20%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[87.87]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "20%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[76.20]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "20%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[76.20]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "20%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[61.13]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "20%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[61.13]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Medium",
                        "corner-cases": "20%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[92.60]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Medium",
                        "Corner-Cases": "20%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[92.60]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "20%",
                        "method": "Word-Occ"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[81.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "20%",
                        "Method": "Word-Occ"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[81.30]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "20%",
                        "method": "RoBERTa"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[83.37]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "20%",
                        "Method": "RoBERTa"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[83.37]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "experiment": "multi-class matching",
                        "table": "Table 5",
                        "dimension": "amount of corner-cases",
                        "development set size": "Large",
                        "corner-cases": "20%",
                        "method": "R-SupCon"
                    },
                    "measures": "[micro-F1]",
                    "outcomes": "[93.03]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Experiment": "Multi-class matching",
                        "Development Set Size": "Large",
                        "Corner-Cases": "20%",
                        "Method": "R-SupCon"
                    },
                    "measures": "[Micro-F1]",
                    "outcomes": "[93.03]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 27,
        "total_ground_truth_claims": 27,
        "number_of_matches": 27
    },
    "1305.2254_6": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "MLN_version": "MLN(Fig1)",
                        "heuristics": "none"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.513, 0.532, 0.602, 0.544]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Cites"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.513]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "MLN_version": "MLN(S&D)",
                        "heuristics": "complex heuristics by Singla and Domingos",
                        "additional_procedure": "TFIDF-based matching with canopies"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.520, 0.573, 0.627, 0.629]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.532]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "MLN_version": "MLN(S&D)",
                        "heuristics": "complex heuristics by Singla and Domingos",
                        "additional_procedure": "TFIDF-based matching with canopies"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.520, 0.573, 0.627, 0.629]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.602]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "MLN_version": "MLN(S&D)",
                        "heuristics": "complex heuristics by Singla and Domingos",
                        "additional_procedure": "TFIDF-based matching with canopies"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.520, 0.573, 0.627, 0.629]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.544]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "MLN_version": "MLN(S&D)",
                        "heuristics": "complex heuristics by Singla and Domingos",
                        "additional_procedure": "TFIDF-based matching with canopies"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.520, 0.573, 0.627, 0.629]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Cites"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.520]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.532]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.602]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.544]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.573]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.627]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.629]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR",
                        "parameter_w": "1"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.680, 0.836, 0.860, 0.908]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Cites",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.680]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.532]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.602]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.544]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.573]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.627]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.629]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.836]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.860]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.908]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "model": "ProPPR"
                    },
                    "measures": "[AUC_cites, AUC_authors, AUC_venues, AUC_titles]",
                    "outcomes": "[0.800, 0.840, 0.869, 0.900]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Cites"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.800]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.532]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.602]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(Fig1)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.544]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.573]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.627]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "MLN(S&D)",
                        "Trained with": "State-of-the-art Alchemy system",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.629]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.836]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.860]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles",
                        "w": "1"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.908]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Authors"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.840]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Venues"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.869]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "table": "Table 6",
                        "task": "citation-matching",
                        "dataset": "CORA",
                        "evaluation_procedure": "same for all models",
                        "training_system": "Alchemy",
                        "training_commands": "recommended commands for CORA",
                        "comparison": "ProPPR vs MLN(S&D)",
                        "result": "title performance not reported by Singla and Domingos"
                    }
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "ProPPR",
                        "Dataset": "CORA citation-matching",
                        "Task": "Titles"
                    },
                    "measures": "[AUC]",
                    "outcomes": "[0.900]"
                },
                "match": "no"
            }
        ],
        "total_extracted_claims": 5,
        "total_ground_truth_claims": 16,
        "number_of_matches": 4
    },
    "2003.04238_8": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.756]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.223]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.455]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.204, 0.768]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.326, 0.756]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.326, 0.756]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.326, 0.756]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Bayesian",
                        "specification": "baseline",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.326, 0.756]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.756]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.223, 0.763]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.223, 0.763]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.223, 0.763]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.223, 0.763]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.223]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.455]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "common names",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.361, 0.773]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.455, 0.657]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.455]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,1,2)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.389, 0.824]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.359, 0.746]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,2,4)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.301, 0.922]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[TPR, PPV]",
                    "outcomes": "[0.315, 0.770]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.204]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.326]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "baseline",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.768]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.361]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.763]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "common names",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.773]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.389]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.657]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,1,2)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.824]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.359]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.301]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.746]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,2,4)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.922]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[TPR]",
                    "outcomes": "[0.315]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated TPR]",
                    "outcomes": "[0.263]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[PPV]",
                    "outcomes": "[0.770]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "-",
                        "specification": "record-specific",
                        "parameters": "\u03bb=(1,3,6)",
                        "context": "Union Army dataset",
                        "source": "expert-linked matches",
                        "reliability": "unreliable when nA<<nB"
                    },
                    "measures": "[est. TPR, est. PPV]",
                    "outcomes": "[0.263, 0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Bayesian",
                        "Specification": "record-specific",
                        "Parameters": "\u03bb=(1,3,6)",
                        "Dataset": "Union Army"
                    },
                    "measures": "[Estimated PPV]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            }
        ],
        "total_extracted_claims": 10,
        "total_ground_truth_claims": 20,
        "number_of_matches": 3
    },
    "1704.02450_3": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "Original WLD",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[74.34]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Original WLD",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[74.34]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "SIFT",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[76.28]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "SIFT",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[76.28]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "EUCLBP",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[79.36]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "EUCLBP",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[79.36]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "LFDA",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[81.43]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "LFDA",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[81.43]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "MCWLD",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[84.24]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "MCWLD",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[84.24]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "VGG",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[80.89, 72.08]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[80.89]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CenterLoss",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[84.07, 76.20]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CenterLoss",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[84.07, 76.20]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[84.07]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "Light CNN",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[84.07, 75.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "Light CNN",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[84.07, 75.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "Light CNN",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[84.07, 75.30]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[84.07]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[85.35, 82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[85.35, 82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[85.35, 82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[75.30]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1, FAR=1%]",
                    "outcomes": "[85.35, 82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CDL",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[Rank-1 Accuracy]",
                    "outcomes": "[85.35]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[75.30]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CDL",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[75.30]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "method": "CDL",
                        "training dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CDL",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[82.52]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "small number of training samples"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "small number of training samples"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "small number of training samples"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[85.35]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[75.30]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "more sketch-photo images"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[improved performance]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "VGG",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[72.08]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "more sketch-photo images"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[improved performance]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "CenterLoss",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[76.20]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "evaluation": "viewed sketch-photo face recognition",
                        "database": "IIIT-D Sketch Database",
                        "training dataset": "CUFSF",
                        "context": "more sketch-photo images"
                    },
                    "measures": "[Rank-1]",
                    "outcomes": "[improved performance]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Light CNN",
                        "Dataset": "IIIT-D Sketch Database",
                        "Training Dataset": "CUFSF"
                    },
                    "measures": "[VR@FAR=1%]",
                    "outcomes": "[75.30]"
                },
                "match": "no"
            }
        ],
        "total_extracted_claims": 13,
        "total_ground_truth_claims": 13,
        "number_of_matches": 10
    },
    "2005.09399_9": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "airports",
                        "link type": "umbel:isLike",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[97.47%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "airports",
                        "Link Type": "umbel:isLike",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[97.47]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "airlines",
                        "link type": "umbel:isLike",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[99.75%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "airlines",
                        "Link Type": "umbel:isLike",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[99.75]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "twitter",
                        "link type": "dct:subject",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[9.52%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "twitter",
                        "Link Type": "dct:subject",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[9.52]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "books",
                        "link type": "dct:subject",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[63.55%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "books",
                        "Link Type": "dct:subject",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[63.55]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "iati",
                        "link type": "dct:subject",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[49.13%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "iati",
                        "Link Type": "dct:subject",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[49.13]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "iati",
                        "link type": "dct:coverage",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[39.46%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "iati",
                        "Link Type": "dct:coverage",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[39.46]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "dataset": "www2012",
                        "link type": "foaf:based_near",
                        "blocking method": "token blocking",
                        "evaluation metric": "recall"
                    },
                    "measures": "[recall]",
                    "outcomes": "[62.61%]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "www2012",
                        "Link Type": "foaf:based_near",
                        "Blocking Method": "token blocking"
                    },
                    "measures": "[Recall]",
                    "outcomes": "[62.61]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 16,
        "total_ground_truth_claims": 7,
        "number_of_matches": 7
    },
    "1906.11180_2": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4102, 0.4832]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.4102]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5060, 0.5458]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5060, 0.5458]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.5060]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5916, 0.5923]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5916, 0.5923]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5916, 0.5923]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.5916]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4686, 0.5566]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4686, 0.5566]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4686, 0.5566]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4686, 0.5566]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.4686]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5295, 0.5649]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5295, 0.5649]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5295, 0.5649]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5295, 0.5649]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5295, 0.5649]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.5295]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5977, 0.5985]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.5977]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.4728, 0.5590]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.4728]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.5420, 0.5912]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.5420]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "pre-training",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6049, 0.6052]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6049]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6506, 0.6948]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6506]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6859, 0.6989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6859]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "MLP",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6429, 0.6626]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6429]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7008, 0.7434]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.7008]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7434]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7167, 0.7372]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.7167]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7434]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7372]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "BiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6697, 0.6850]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6697]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7434]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7372]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6850]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "independent"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7286, 0.7557]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.7286]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7434]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7372]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6850]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7557]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.7429, 0.7601]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.7429]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.4832]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5458]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5923]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5566]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5649]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5985]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5590]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.5912]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Pre-training",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6052]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6948]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "MLP",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6626]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7434]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7372]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "BiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.6850]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Independent"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7557]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = -0.1)"
                    },
                    "measures": "[AvgF1@top5]",
                    "outcomes": "[0.7601]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "framework": "S-Lite",
                        "evaluation": "typing performance",
                        "setting": "fine tuning",
                        "model": "AttBiRNN",
                        "typing strategy": "hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all, AvgF1@top5]",
                    "outcomes": "[0.6918, 0.7070]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Framework": "AttBiRNN",
                        "Setting": "Fine tuning",
                        "Dataset": "S-Lite",
                        "Typing Strategy": "Hierarchical (kappa = 0)"
                    },
                    "measures": "[AvgF1@all]",
                    "outcomes": "[0.6918]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 18,
        "total_ground_truth_claims": 36,
        "number_of_matches": 18
    },
    "2312.03987_7": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[80.66]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[80.66]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[78.05]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[78.05]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[78.66]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "WA",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[78.66]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[88.38]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[88.38]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[84.23]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[84.23]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[87.06]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AB",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[87.06]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[62.16]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[62.16]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[59.90]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[59.90]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[59.20]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "AG",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[59.20]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[83.70]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[83.70]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[81.27]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[81.27]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[80.91]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DS",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[80.91]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[94.96]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[94.96]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[92.70]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[92.70]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[90.36]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "DA",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[90.36]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[100.00]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[100.00]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[93.62]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[93.62]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[95.24]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "FZ",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[95.24]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[96.43]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[96.43]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[90.57]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[90.57]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[90.91]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "IA",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[90.91]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "BatchER-LR",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[96.55]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-LR"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[96.55]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "BatchER-JAC",
                        "Type": "Structure-aware",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[89.66]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "Structure-aware",
                        "Model": "BatchER-JAC"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[89.66]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "BatchER-SEM",
                        "Type": "Semantics-based",
                        "Evaluation Metric": "Matching Accuracy"
                    },
                    "measures": "[91.67]",
                    "outcomes": "[]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Dataset": "Beer",
                        "Feature Extractor": "Semantics-based",
                        "Model": "BatchER-SEM"
                    },
                    "measures": "[Matching Accuracy]",
                    "outcomes": "[91.67]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 29,
        "total_ground_truth_claims": 24,
        "number_of_matches": 24
    },
    "1711.07424_2": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "1",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[0.8]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "1",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[0.8]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "2",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[2.9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "2",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[2.9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "3",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[0.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "3",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[0.7]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "4",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[1.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "4",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[1.7]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "5",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[1.4]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "5",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[1.4]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "6",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[0.5]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "6",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[0.5]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "7",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[1.0]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "7",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[1.0]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "8",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[0.9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "8",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[0.9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "GB vs RW",
                        "region": "average",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[0.94]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "GB vs RW",
                        "Region": "Average",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[0.94]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "1",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[60.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "1",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[60.6]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "2",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[209]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "2",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[209]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "3",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[36.2]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "3",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[36.2]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "4",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[127]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "4",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[127]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "5",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[48.9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "5",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[48.9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "6",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[104]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "6",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[104]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "7",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[172]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "7",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[172]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "8",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[33.3]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "8",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[33.3]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "LB vs RW",
                        "region": "average",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[94.0]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "LB vs RW",
                        "Region": "Average",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[94.0]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "1",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[6.3]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "1",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[6.3]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "2",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[20.3]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "2",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[20.3]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "3",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[3.7]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "3",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[3.7]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "4",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[15.3]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "4",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[15.3]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "5",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[7.2]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "5",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[7.2]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "6",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[10.9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "6",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[10.9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "7",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[15.6]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "7",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[15.6]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "8",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[3.1]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "8",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[3.1]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "comparison": "HB vs RW",
                        "region": "average",
                        "efficiency measure": "ESS/time",
                        "summary statistics": "5",
                        "summary statistic type": "Hamming distance",
                        "computation method": "coda R package",
                        "reference": "Plummer et al., 2006"
                    },
                    "measures": "[efficiency]",
                    "outcomes": "[9.96]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Comparison": "HB vs RW",
                        "Region": "Average",
                        "Efficiency Measure": "Effective Sample Sizes per Unit of Computation Time",
                        "Computation Method": "coda R package",
                        "Summary Statistics": "Hamming Distance from Posterior Matching"
                    },
                    "measures": "[Relative Efficiency]",
                    "outcomes": "[9.96]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 27,
        "total_ground_truth_claims": 27,
        "number_of_matches": 27
    },
    "2503.24193_3": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "model": "BM25",
                        "how_it_works": "Keyword indexing",
                        "task": "generative track retrieval",
                        "comparison": "baselines",
                        "effectiveness_proven_by": "hits@10",
                        "closest_competitor": "Bi-encoder fine-tuned"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.101]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "BM25",
                        "How it works": "Keyword indexing",
                        "Task": "Generative track retrieval"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.101]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "model": "Bi-encoder zero-shot",
                        "how_it_works": "Semantic match between playlist titles",
                        "task": "generative track retrieval",
                        "comparison": "baselines",
                        "effectiveness_proven_by": "hits@10",
                        "closest_competitor": "Bi-encoder fine-tuned"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.065]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "Bi-encoder zero-shot",
                        "How it works": "Semantic match between playlist titles",
                        "Task": "Generative track retrieval"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.065]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "model": "Bi-encoder fine-tuned",
                        "how_it_works": "Fine-tuned semantic match between playlist titles",
                        "task": "generative track retrieval",
                        "comparison": "baselines",
                        "effectiveness_proven_by": "hits@10",
                        "closest_competitor": "Text2Tracks"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.119]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "Bi-encoder fine-tuned",
                        "How it works": "Fine-tuned semantic match between playlist titles",
                        "Task": "Generative track retrieval"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.119]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "model": "Text2Tracks",
                        "how_it_works": "GR using cf-based semantic-ids",
                        "task": "generative track retrieval",
                        "comparison": "baselines",
                        "effectiveness_proven_by": "hits@10",
                        "closest_competitor": "Bi-encoder fine-tuned",
                        "increase_in_hits@10": "127%"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.270]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Model": "Text2Tracks",
                        "How it works": "GR using cf-based semantic-ids",
                        "Task": "Generative track retrieval"
                    },
                    "measures": "[hits@10]",
                    "outcomes": "[0.270]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 4,
        "total_ground_truth_claims": 5,
        "number_of_matches": 4
    },
    "2205.10678_1": {
        "matches": [
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.934]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.934]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "99%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.779]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.779]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.997]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.71]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.49]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.949]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.9]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.896]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.695]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.945]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.918]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[1.0]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.906]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.834]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.905]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "99%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.997]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.997]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "95%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.71]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.71]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost",
                        "precision threshold": "99%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.49]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.49]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.949]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.949]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "99%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.9]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.9]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.989]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.896]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.695]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.945]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.918]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[1.0]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.906]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.834]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.905]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "99%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.989]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.989]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "95%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.896]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.896]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "XGBoost + top all",
                        "precision threshold": "99%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.695]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "XGBoost + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.695]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.945]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.945]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "99%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.918]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.918]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[1.0]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.906]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.834]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.905]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "99%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[1.0]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "with ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[1.0]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "95%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.906]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "95%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.906]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Cascade 4 + top all",
                        "precision threshold": "99%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.834]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Cascade 4 + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.834]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "95%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.905]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "95%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "99%",
                        "category": "all"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.905]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "all",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.905]"
                },
                "match": "yes"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "95%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "99%",
                        "category": "with ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "95%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[NA]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "no"
            },
            {
                "Extracted_claim": {
                    "subject": {
                        "method": "Chain + top all",
                        "precision threshold": "99%",
                        "category": "without ID"
                    },
                    "measures": "[mean recall]",
                    "outcomes": "[0.816]"
                },
                "Ground_truth_claim": {
                    "subject": {
                        "Method": "Chain + top all",
                        "Category": "without ID",
                        "Precision Threshold": "99%"
                    },
                    "measures": "[Mean Recall]",
                    "outcomes": "[0.816]"
                },
                "match": "yes"
            }
        ],
        "total_extracted_claims": 24,
        "total_ground_truth_claims": 17,
        "number_of_matches": 17
    }
}