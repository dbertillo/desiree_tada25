{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[3.7155, 3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Evaluation Scale": "1-5",
                    "Evaluation Metrics": "Accuracy, Appropriateness"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[4.2722]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 1",
                    "Evaluation Metric": "F1"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 2",
                    "Evaluation Metric": "R@1"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "BLEU-1"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "METEOR"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Baseline",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "Rouge-L"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "Rouge-L"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "Our system",
                    "DSTC": "9",
                    "Sub-task": "Sub-task 3",
                    "Evaluation Metric": "Rouge-L"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 12,
    "total_ground_truth_claims": 14,
    "number_of_matches": 12
}