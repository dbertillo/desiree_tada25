{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Team": "11",
                    "System": "our",
                    "Pipeline": "various stages",
                    "Sub-tasks": "individual",
                    "Tasks": "downstream",
                    "Model": "T5",
                    "Fine-tuning": "sub-tasks",
                    "Evaluation": "human",
                    "Scale": "1-5"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[4.2722]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "3",
                    "F1": "0.9675",
                    "R@1": "0.8702",
                    "BLEU-1": "0.3743",
                    "METEOR": "0.3854",
                    "Rouge-L": "0.3797"
                },
                "measures": "[Accuracy, Appropriateness]",
                "outcomes": "[4.2722, 4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[4.2619]"
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 2,
    "total_ground_truth_claims": 14,
    "number_of_matches": 1
}