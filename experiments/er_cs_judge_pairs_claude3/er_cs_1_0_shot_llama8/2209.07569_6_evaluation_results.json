{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "P": ".829",
                    "R": ".991",
                    "F": ".901",
                    "Acc": ".960",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.829, 0.991, 0.901, 0.960, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "P": ".829",
                    "R": ".991",
                    "F": ".901",
                    "Acc": ".960",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.829, 0.991, 0.901, 0.960, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "P": ".829",
                    "R": ".991",
                    "F": ".901",
                    "Acc": ".960",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.829, 0.991, 0.901, 0.960, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.901]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "P": ".921",
                    "R": ".905",
                    "F": ".912",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.921, 0.905, 0.912, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "P": ".921",
                    "R": ".905",
                    "F": ".912",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.921, 0.905, 0.912, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "P": ".921",
                    "R": ".905",
                    "F": ".912",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.921, 0.905, 0.912, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "P": ".921",
                    "R": ".905",
                    "F": ".912",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.921, 0.905, 0.912, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "P": ".921",
                    "R": ".905",
                    "F": ".912",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.921, 0.905, 0.912, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.905]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[57.6 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "P": ".852",
                    "R": ".812",
                    "F": ".831",
                    "Acc": ".969",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.852, 0.812, 0.831, 0.969, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.812]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[57.6 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "P": ".854",
                    "R": ".772",
                    "F": ".810",
                    "Acc": ".966",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.854, 0.772, 0.810, 0.966, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.772]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[57.6 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[7.7 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "P": ".786",
                    "R": ".745",
                    "F": ".761",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.786, 0.745, 0.761, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.761]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[57.6 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[7.7 %]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "P": ".808",
                    "R": ".713",
                    "F": ".757",
                    "Acc": ".948",
                    "EFsubscriptE_{F}": "-"
                },
                "measures": "[Dataset, Model, P, R, F, Acc, EFsubscriptE_{F}]",
                "outcomes": "[0.808, 0.713, 0.757, 0.948, -]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.713]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "57.6 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[57.6]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[57.6 %]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "7.7 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[7.7]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[7.7 %]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.757]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.775]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.788]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.782]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.950]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "FlexER",
                    "EFsubscriptE_{F}": "8.8 %"
                },
                "measures": "[Model, EFsubscriptE_{F}]",
                "outcomes": "[8.8]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[E_subscript{F}]",
                "outcomes": "[8.8 %]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.757]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.775]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.788]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.782]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Caption": "Table 6",
                    "Description": "Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}"
                },
                "measures": "[Caption, Description]",
                "outcomes": "[Table 6, Equivalence intent results in terms of precision (P), recall (R), F1 (F), Acc and EFsubscriptE_{F}]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.950]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.757]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.775]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.788]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.782]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table6",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table6, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for equivalence intent solely, which is the universal entity resolution interpretation]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.950]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.757]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.775]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.788]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.782]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Table7",
                    "Description": "provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Table7, provides results in terms of precision (PP), recall (RR), F1 measure (FF), Accuracy (AccAcc) and EFsubscriptE_{F} (see Section5.2.3) for all datasets and their intents (except the equivalence intent that is reported in Table6)]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.950]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.829]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.991]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.960]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.921]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.912]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.933]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.958]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "AmazonMI",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.852]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.831]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.969]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.854]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.810]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.966]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.903]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.792]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.844]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "Walmart-Amazon",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.985]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.786]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.745]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "In-parallel",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.808]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.757]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "Multi-label",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.948]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Precision]",
                "outcomes": "[.775]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Recall]",
                "outcomes": "[.788]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[F1]",
                "outcomes": "[.782]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Citation": "Section5.4.1",
                    "Description": "compare FlexER with the same baselines as in"
                },
                "measures": "[Citation, Description]",
                "outcomes": "[Section5.4.1, compare FlexER with the same baselines as in]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Dataset": "WDC",
                    "Model": "FlexER",
                    "Intent": "Equivalence"
                },
                "measures": "[Accuracy]",
                "outcomes": "[.950]"
            },
            "match": "no"
        }
    ],
    "total_extracted_claims": 13,
    "total_ground_truth_claims": 39,
    "number_of_matches": 9
}