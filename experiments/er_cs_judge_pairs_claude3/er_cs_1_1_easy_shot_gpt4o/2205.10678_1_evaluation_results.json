{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.934]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.934]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.779]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.779]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.997]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.997]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.71]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.71]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.49]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.49]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.949]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.949]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.9]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.9]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.989]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.989]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.896]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.896]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.695]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "XGBoost + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.695]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.945]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "all",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.945]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.918]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.918]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[1.0]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "with ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[1.0]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.906]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "without ID",
                    "Precision Threshold": "95%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.906]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.834]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Cascade 4 + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.834]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.905]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain + top all",
                    "Category": "all",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.905]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Method": "Chain + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.816]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Method": "Chain + top all",
                    "Category": "without ID",
                    "Precision Threshold": "99%"
                },
                "measures": "[Mean Recall]",
                "outcomes": "[0.816]"
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 17,
    "total_ground_truth_claims": 17,
    "number_of_matches": 17
}