{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Baseline"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9455]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 1",
                    "System": "Our system"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 1",
                    "Dataset": "DSTC9"
                },
                "measures": "[F1]",
                "outcomes": "[0.9675]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Baseline"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.6201]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 2",
                    "System": "Our system"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 2",
                    "Dataset": "DSTC9"
                },
                "measures": "[R@1]",
                "outcomes": "[0.8702]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Baseline"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3031]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[BLEU-1]",
                "outcomes": "[0.3743]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Baseline"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.2983]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[METEOR]",
                "outcomes": "[0.3854]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Baseline"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3039]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Sub-task": "Sub-task 3",
                    "System": "Our system"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Sub-task": "Sub-task 3",
                    "Dataset": "DSTC9"
                },
                "measures": "[Rouge-L]",
                "outcomes": "[0.3797]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Metric": "Accuracy",
                    "System": "Baseline"
                },
                "measures": "[Value]",
                "outcomes": "[3.7155]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[3.7155]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Metric": "Accuracy",
                    "System": "Our system"
                },
                "measures": "[Value]",
                "outcomes": "[4.2722]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Metric": "Accuracy",
                    "System": "Our system"
                },
                "measures": "[Value]",
                "outcomes": "[4.2722]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Accuracy]",
                "outcomes": "[4.2722]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Metric": "Appropriateness",
                    "System": "Baseline"
                },
                "measures": "[Value]",
                "outcomes": "[3.9386]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Baseline",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[3.9386]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Metric": "Appropriateness",
                    "System": "Our system"
                },
                "measures": "[Value]",
                "outcomes": "[4.2619]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "System": "Our system",
                    "Dataset": "DSTC9",
                    "Evaluation": "Human evaluation on a scale of 1-5"
                },
                "measures": "[Appropriateness]",
                "outcomes": "[4.2619]"
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 19,
    "total_ground_truth_claims": 14,
    "number_of_matches": 14
}