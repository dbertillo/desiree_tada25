{
    "matches": [
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Recommended for CORA citation-matching data",
                    "Reproducibility Note": "Results reproduced here differ from previously reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.513]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.513]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Recommended for CORA citation-matching data",
                    "Reproducibility Note": "Results reproduced here differ from previously reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.532]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.532]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.520]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.520]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.520]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.520]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.573]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.573]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Reproducibility Note": "Results not identical to previous-reported ones",
                    "Heuristic Note": "Singla and Domingos used complex heuristics difficult to reproduce",
                    "Heuristic Example": "Combining MLNs with TFIDF-based matching procedure based on canopies"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.573]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.573]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.680]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.680]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.680]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.680]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.680]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.680]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.836]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.836]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.836]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.836]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR(w=1)",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.836]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.836]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Cites]",
                "outcomes": "[0.800]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Cites"
                },
                "measures": "[AUC]",
                "outcomes": "[0.800]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Authors]",
                "outcomes": "[0.840]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Authors"
                },
                "measures": "[AUC]",
                "outcomes": "[0.840]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Venues]",
                "outcomes": "[0.869]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.869]"
            },
            "match": "yes"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.602]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(Fig1)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.544]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues"
                },
                "measures": "[AUC]",
                "outcomes": "[0.627]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "MLN(S&D)",
                    "Trained with": "State-of-the-art Alchemy system",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.629]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Venues",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.860]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles",
                    "w": "1"
                },
                "measures": "[AUC]",
                "outcomes": "[0.908]"
            },
            "match": "no"
        },
        {
            "Extracted_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Evaluation Procedure": "Same for all results in Table 6",
                    "Training System": "Alchemy",
                    "Training Commands": "Not specified",
                    "Heuristic Note": "No complex heuristics used",
                    "Heuristic Example": "None"
                },
                "measures": "[AUC Titles]",
                "outcomes": "[0.900]"
            },
            "Ground_truth_claim": {
                "subject": {
                    "Model": "ProPPR",
                    "Dataset": "CORA citation-matching",
                    "Task": "Titles"
                },
                "measures": "[AUC]",
                "outcomes": "[0.900]"
            },
            "match": "yes"
        }
    ],
    "total_extracted_claims": 10,
    "total_ground_truth_claims": 16,
    "number_of_matches": 10
}